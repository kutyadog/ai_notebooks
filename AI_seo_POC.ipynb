{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kutyadog/ai_notebooks/blob/main/AI_seo_POC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JagPHRRqr2YR"
      },
      "source": [
        "# Ai-SEO-tests\n",
        "\n",
        "Dec. 2023. - Early stage POC - SEO Analysis driven by AI. Some functionality removed for legal reasons.\n",
        "\n",
        "Project was demo'd & well recieved; advanced to a production level and launched July 2024.\n",
        "\n",
        "Questions regarding code, please feel free to reach out at kutyadog@gmail.com (Chris Johnson).\n",
        "\n",
        "NOTE: Not all functions here will work outside wapo VPN. Keys & internal URLs removed for obvious security reasons.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qCIcgkOnWC3l"
      },
      "outputs": [],
      "source": [
        "# @title Start it up!\n",
        "\n",
        "!pip install -q gradio==3.41.0\n",
        "# !pip install -q gradio\n",
        "# !pip install https://gradio-builds.s3.amazonaws.com/fbcd9a9acef733f106b5138a61fce2190c12c76c/gradio-3.45.1-py3-none-any.whl\n",
        "!pip install beautifulsoup4\n",
        "# !pip install rake-nltk\n",
        "!pip install keybert\n",
        "!pip install -U textblob\n",
        "!python -m textblob.download_corpora\n",
        "!pip install -q openai\n",
        "!pip install pytrends\n",
        "\n",
        "import gradio\n",
        "import requests\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import gradio\n",
        "import requests\n",
        "import json\n",
        "\n",
        "from keybert import KeyBERT\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# globals!\n",
        "search_results_array = [] #gr.Array()\n",
        "open_ai_model = \"gpt-4-1106-preview\"\n",
        "open_ai_max_tokens = 8500\n",
        "open_ai_temp = 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLtBMKqwPzLw"
      },
      "source": [
        "## Necessary Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "h72AjW4jY3Yf"
      },
      "outputs": [],
      "source": [
        "# @title Story Utility functions\n",
        "\n",
        "def get_story_headline(element):\n",
        "  try:\n",
        "    item = element['headlines']['basic']\n",
        "  except KeyError:\n",
        "    item = ''\n",
        "  return str(item)\n",
        "\n",
        "def get_story_title(element):\n",
        "  try:\n",
        "    item = element['headlines']['meta_title'] # + \" - The Washington Post\"\n",
        "  except KeyError:\n",
        "    item = ''\n",
        "  if item == '':\n",
        "    try:\n",
        "      item = element['headlines']['basic']\n",
        "    except KeyError:\n",
        "      item = ''\n",
        "  return str(item)\n",
        "\n",
        "def get_story_description(element):\n",
        "  try:\n",
        "    item = element['description']['basic']\n",
        "  except KeyError:\n",
        "    item = ''\n",
        "  return str(item)\n",
        "\n",
        "def get_id(element):\n",
        "  try:\n",
        "    item = element['_id']\n",
        "  except KeyError:\n",
        "    item = ''\n",
        "  return str(item)\n",
        "\n",
        "def get_content_elements(element):\n",
        "  try:\n",
        "    item = element['content_elements']\n",
        "  except KeyError:\n",
        "    item = ''\n",
        "  return item\n",
        "\n",
        "def get_story_section_path(element):\n",
        "  try:\n",
        "    item = element['taxonomy.primary_section.path']\n",
        "  except KeyError:\n",
        "    item = ''\n",
        "\n",
        "  if item == '':\n",
        "    try:\n",
        "      item = element['additional_properties']['commercial_node']\n",
        "    except KeyError:\n",
        "      item = ''\n",
        "\n",
        "  if item == '':\n",
        "    try:\n",
        "      item = element['taxonomy']['primary_site']['_id']\n",
        "    except KeyError:\n",
        "      item = ''\n",
        "\n",
        "  return str(item)\n",
        "\n",
        "def get_story_canonical_url(element):\n",
        "  try:\n",
        "    item = element['headlines']['url']\n",
        "  except KeyError:\n",
        "    item = ''\n",
        "\n",
        "  if item == '':\n",
        "    try:\n",
        "      item = element['canonical_url']\n",
        "    except KeyError:\n",
        "      item = ''\n",
        "\n",
        "  return str(item)\n",
        "\n",
        "def get_story_publish_date(element):\n",
        "  try:\n",
        "    item = element['publish_date']\n",
        "  except KeyError:\n",
        "    item = ''\n",
        "  return str(item)\n",
        "\n",
        "def get_story_slug(element):\n",
        "  try:\n",
        "    item = element['slug']\n",
        "  except KeyError:\n",
        "    item = ''\n",
        "  return str(item)\n",
        "\n",
        "def get_story_type(element):\n",
        "  try:\n",
        "    item = element['type']\n",
        "  except KeyError:\n",
        "    item = ''\n",
        "  return str(item)\n",
        "\n",
        "def get_story_subtype(element):\n",
        "  try:\n",
        "    item = element['subtype']\n",
        "  except KeyError:\n",
        "    item = ''\n",
        "  return str(item)\n",
        "\n",
        "def count_keywords(this_string, keywordsArray):\n",
        "  count = 0\n",
        "  for keyword in keywordsArray:\n",
        "    if keyword.lower() in str(this_string).lower():\n",
        "      count += 1\n",
        "  return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "D43DJ7hQWKWQ"
      },
      "outputs": [],
      "source": [
        "# @title Prism functions\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "prism_key = userdata.get('WAPO_PRISM_KEY')\n",
        "\n",
        "def get_prism_data_from_url(url):\n",
        "  fixed_url = url.replace('https://www.washingtonpost.com', '')\n",
        "  fixed_url = fixed_url.replace('https://washingtonpost.com', '')\n",
        "  if fixed_url[-1] != '/' and not fixed_url.endswith(\"_story.html\") :\n",
        "    fixed_url += '/'\n",
        "  fullpath = f\"https://prism.ext.nile.works/content/v4?website=washpost&key={prism_key}&website_url={fixed_url}&website=washpost\"\n",
        "  response = requests.get(fullpath)\n",
        "  my_json_object = json.loads(response.content)\n",
        "  return my_json_object\n",
        "\n",
        "# story_object = get_prism_data_from_url(\"https://www.washingtonpost.com/sports/2023/10/01/taylor-swift-kelce-chiefs-jets/\")\n",
        "\n",
        "\n",
        "\n",
        "def get_prism_search_data_by_query(query):\n",
        "  # CHRIS THIS IS THE NEW PATH WITH ONLY FIELDS YOU WANT:\n",
        "  # https://prism.wpit.nile.works/content/v4/search/?website=washpost&sort=last_updated_date:desc&from=0&size=20&body=%7B%22query%22:%7B%22bool%22:%7B%22must%22:%5B%7B%22term%22:%7B%22type%22:%22story%22%7D%7D,%7B%22match_phrase_prefix%22:%7B%22slug%22:%22linkbox%22%7D%7D,%7B%22term%22:%7B%22revision.published%22:%22true%22%7D%7D,%7B%22range%22:%7B%22last_updated_date%22:%7B%7D%7D%7D,%7B%22match_phrase_prefix%22:%7B%22source.system%22:%22ellipsis%22%7D%7D%5D,%22must_not%22:%5B%7B%22match_phrase%22:%7B%22subtype%22:%22live-all%22%7D%7D,%7B%22match_phrase%22:%7B%22subtype%22:%22live-update%22%7D%7D,%7B%22match_phrase%22:%7B%22subtype%22:%22live-reporter-insight%22%7D%7D,%7B%22match_phrase%22:%7B%22subtype%22:%22live-race-call%22%7D%7D,%7B%22match_phrase%22:%7B%22subtype%22:%22live-faq%22%7D%7D,%7B%22match_phrase%22:%7B%22taxonomy.tags.slug%22:%22ellipsis-template%22%7D%7D%5D%7D%7D%7D&&_sourceInclude=headlines.basic,headlines.meta_title,headlines.url,canonical_url,content_elements.type,content_elements.content,additional_properties.commercial_node,description.basic,publish_date,slug,type,subtype,taxonomy.primary_section.path,taxonomy.primary_section._id,website_url\n",
        "\n",
        "  #https://prism.ext.nile.works/content/v4/search/published?q=+headlines.basic:\"lewiston\"+subtype:\"default\"&nocache=true&s=date&from=0&t=story&size=30&sort=display_date:desc&website=washpost&key={prism_key}\n",
        "  # query_text = 'q=+headlines.basic:\"'+ query +'\" AND (subtype:default)'\n",
        "  query_text = 'q=+headlines.basic:\"'+ query +'\" AND !(subtype:live-all) AND !(subtype:live-update) AND !(subtype:live-reporter-insight)'\n",
        "  query_text += ' AND !(canonical_url:\"\")'\n",
        "  query_text += ' AND (type:\"story\")'\n",
        "\n",
        "  fullpath = 'https://prism.ext.nile.works/content/v4/search/published?{}&nocache=true&s=date&from=0&t=story&size=30&sort=display_date:desc&website=washpost&key={}'.format(\n",
        "      query_text,\n",
        "      prism_key\n",
        "  )\n",
        "\n",
        "  # +subtype:\"default\" # removes live\n",
        "  # print(fullpath)\n",
        "  response = requests.get(fullpath)\n",
        "  my_json_object = json.loads(response.content)\n",
        "  return my_json_object\n",
        "\n",
        "# search_object = get_prism_search_data_by_query(\"Taylor Swift comes to NFL\")\n",
        "# search_object\n",
        "\n",
        "\n",
        "# get_prism_search_data_by_query('taylor swift')\n",
        "# https://prism.wpit.nile.works/content/v4/search/?q=+headlines.basic:\"Taylor Swift comes to\"&website=washpost\n",
        "# https://prism.wpit.nile.works/content/v4/search/?q=%2Bheadlines.basic%3A%22Taylor%20Swift%20comes%20to%22&website=washpost\n",
        "# https://prism.ext.nile.works/content/v4/search/?q=%2Bheadlines.basic%3A%22Taylor%20Swift%20comes%20to%22&website=washpost&key={prism_key}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xo54ZrGxOCH3"
      },
      "outputs": [],
      "source": [
        "# @title Interface functions\n",
        "\n",
        "def get_html_score_from_url(url):\n",
        "  global story_object\n",
        "  story_object = get_prism_data_from_url(url)\n",
        "  return get_html_score_from_story_object(story_object)\n",
        "\n",
        "def get_html_score_from_story_object(this_story_object):\n",
        "  global score_object, ai_score_object\n",
        "  score_object, this_story_object = analyze_seo_by_story_object(this_story_object)\n",
        "  story_html_string = get_full_story_html_api(this_story_object)\n",
        "\n",
        "  # ----------------RECIRC LINKS -------------- ONLY call if score is yellow or Red!!!\n",
        "  reCircLinks = get_recirc_links_from_storyObject(this_story_object) # if score_object['recirc_links']['score'] != \"Green\" else []\n",
        "\n",
        "  # ----------------AI Story summary #2 --------------\n",
        "  ai_score_object = ai_score_story(this_story_object, story_html_string)\n",
        "  if \"error\" in ai_score_object:\n",
        "      print(ai_score_object['error'])\n",
        "      return(f\"----ERROR: fn: ai_score_story - OpenAI API returned an API Error: {ai_score_object}\")\n",
        "\n",
        "  ai_score_object = score_seo_keywords(ai_score_object, this_story_object)\n",
        "\n",
        "  # {\n",
        "      # 'keywords': 'Hamas, Israel, Gaza, attack, Palestinian, Iran',\n",
        "      # 'headline_score': 'Yellow',\n",
        "      # 'headline_comment': 'The headline could be more specific about the nature of the attack and its implications.',\n",
        "      # 'meta_title_score': 'Yellow',\n",
        "      # 'meta_title_comment': 'The meta title should include the year of the attack for clarity and to differentiate from past events.',\n",
        "      # 'meta_description_score': 'Yellow',\n",
        "      # 'meta_description_comment': 'The meta description is too vague and does not provide enough detail about the recent events or the historical context.',\n",
        "      # 'meta_descriptions': \"Exploring the reasons behind Hamas's 2023 attack on Israel and the escalating conflict.\n",
        "      #     ** A detailed look at the Gaza-Israel conflict following Hamas's recent attack.\n",
        "      #     ** Unpacking the latest surge in violence between Hamas and Israel, and the global implications.\"\n",
        "  # }\n",
        "\n",
        "  return convert_score_object_to_html(score_object, reCircLinks, this_story_object, ai_score_object)\n",
        "\n",
        "# -------- usage example:\n",
        "# response_object = get_recirc_links_from_ai(\"Taylor Swift comes to Chiefs-Jets, and the NFL gets an even bigger spotlight\", \"/sports\", \"https://www.washingtonpost.com/sports/2023/10/01/taylor-swift-kelce-chiefs-jets/\")\n",
        "# response_object[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def interface_search_stories_by_query(xQuery):\n",
        "  print(\"interface_search_stories_by_query\")\n",
        "  global search_results_array\n",
        "  search_results = get_prism_search_data_by_query(xQuery)\n",
        "  search_results_array = search_results['content_elements']\n",
        "  xArray = []\n",
        "  for element in search_results_array:\n",
        "    headline = get_story_headline( element )\n",
        "    item_type = get_story_type( element )\n",
        "    item_subtype = get_story_subtype(element)\n",
        "    canon_url = get_story_canonical_url(element)\n",
        "    xArray.append({\n",
        "        \"Id\": get_id(element),\n",
        "        \"Headline\": headline,\n",
        "        \"Slug\": get_story_slug(element),\n",
        "        \"Published data\": get_story_publish_date(element)\n",
        "    })\n",
        "  df = pd.DataFrame(xArray)\n",
        "  return df\n",
        "\n",
        "# -------- usage example:\n",
        "# interface_search_stories_by_query(\"Lewiston\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRGmfMpxP3q0"
      },
      "outputs": [],
      "source": [
        "# @title SEO scoring functions\n",
        "\n",
        "\n",
        "\n",
        "story_object = ''\n",
        "\n",
        "def analyze_seo_by_url(url):\n",
        "  story_object = get_prism_data_from_url(url)\n",
        "  print( 'analyze_seo_by_url')\n",
        "  print(story_object)\n",
        "\n",
        "  return analyze_seo_by_story_object(story_object)\n",
        "\n",
        "def analyze_seo_by_story_object(story_object):\n",
        "  internal_links_score = _analyze_internal_links(story_object)\n",
        "  print( 'internal_links_score')\n",
        "  print(internal_links_score)\n",
        "  # Analyze the RECIRC links.\n",
        "  recirc_links_score = _analyze_recirc_links(story_object)\n",
        "\n",
        "  # Analyze the headline.\n",
        "  headline_score = _analyze_headline(story_object)\n",
        "  meta_title_score = _analyze_title(story_object)\n",
        "  meta_description_score = _analyze_meta_description(story_object)\n",
        "\n",
        "  # Return the SEO scores.\n",
        "  score_object = {\n",
        "      \"internal_links\": internal_links_score,\n",
        "      \"recirc_links\" : recirc_links_score,\n",
        "      \"headline\": headline_score,\n",
        "      \"title\": meta_title_score,\n",
        "      \"meta_description\": meta_description_score,\n",
        "  }\n",
        "  return score_object, story_object\n",
        "  # return render_results(score_object)\n",
        "\n",
        "def _analyze_headline(story_object):\n",
        "  # Get the length of the headline.\n",
        "    headline = get_story_headline( story_object )\n",
        "    headline_length = len(headline)\n",
        "\n",
        "    # Return the score for the headline.\n",
        "    score = \"Red\"\n",
        "    if headline_length <= 70:\n",
        "      score = \"Green\"\n",
        "    elif headline_length <= 80:\n",
        "      score = \"Yellow\"\n",
        "\n",
        "    head_suggest = '<span class=\"'+ score +'\">&#10008;</span><strong style=\"margin-left:6px;\">Length:</strong> 70 characters or less. ({} chars)'.format(headline_length) if (score != \"Green\") else '<span class=\"Green\">&#10004;</span><strong style=\"margin-left:6px;\">Length:</strong> 70 characters or less. ({} chars)'.format(headline_length)\n",
        "    return {'score': score, 'score_value': headline_length, 'value': headline, 'suggestion': head_suggest}\n",
        "\n",
        "# -------- usage example:\n",
        "# _analyze_headline(story_object)\n",
        "\n",
        "def _analyze_title(story_object):\n",
        "  meta_title = get_story_title( story_object )\n",
        "  meta_title_length = len(meta_title)\n",
        "  # The ideal length for the meta title is 50–60 characters. Google starts to cut off the title tag after 50-60 characters.\n",
        "\n",
        "  # Return the score for the headline.\n",
        "  score = \"Red\"\n",
        "  if meta_title_length <= 60 and meta_title_length >= 50:\n",
        "    score = \"Green\"\n",
        "  elif meta_title_length <= 70 and meta_title_length >= 40:\n",
        "    score = \"Yellow\"\n",
        "\n",
        "  meta_title_suggest = '<span class=\"'+ score +'\">&#10008;</span><strong style=\"margin-left:6px;\">Length:</strong> 50–60 characters. ({} chars)'.format(meta_title_length) if (score != \"Green\") else '<span class=\"Green\">&#10004;</span><strong style=\"margin-left:6px;\">Length:</strong> 50–60 characters. ({} chars)'.format(meta_title_length)\n",
        "  if meta_title_length == 0:\n",
        "    score = \"Red\"\n",
        "    meta_title_suggest = '<div><span class=\"Red\">&#10008;</span><strong style=\"margin-left:6px;\">Meta title is missing.</strong></div>'\n",
        "\n",
        "  return {'score': score, 'score_value': meta_title_length, 'value': meta_title, 'suggestion': meta_title_suggest}\n",
        "\n",
        "# -------- usage example:\n",
        "# _analyze_title(story_object)\n",
        "\n",
        "def _analyze_meta_description(story_object):\n",
        "  # Get the length of the meta description.\n",
        "  meta_description = get_story_description( story_object )\n",
        "  meta_description_length = len(meta_description)\n",
        "\n",
        "  #Return the score for the meta description.\n",
        "  score = \"Red\"\n",
        "  if meta_description_length <= 160 and meta_description_length > 50:\n",
        "    score = \"Green\"\n",
        "  elif meta_description_length <= 180 and meta_description_length > 160:\n",
        "    score = \"Yellow\"\n",
        "  desc_suggest = '<span class=\"'+ score +'\">&#10008;</span><strong style=\"margin-left:6px;\">Length:</strong> 50-160 characters. ({} chars)'.format(meta_description_length) if (score != \"Green\") else '<span class=\"Green\">&#10004;</span><strong style=\"margin-left:6px;\">Length:</strong> 50-160 characters. ({} chars)'.format(meta_description_length)\n",
        "  return {'score': score, 'score_value': meta_description_length, 'value': meta_description, 'suggestion': desc_suggest}\n",
        "\n",
        "# -------- usage example:\n",
        "# _analyze_meta_description(story_object)\n",
        "\n",
        "def _analyze_internal_links(story_object):\n",
        "  print(story_object)\n",
        "  paragraph_count = 0\n",
        "  link_urls_array = []\n",
        "  for element in get_content_elements(story_object):\n",
        "    if ( element['type'] == \"text\" ):\n",
        "      paragraph_count = paragraph_count + 1\n",
        "      if \"<a href=\" in element['content']:\n",
        "        soup = BeautifulSoup(element['content'], \"html.parser\")\n",
        "        for link in soup.find_all('a'):\n",
        "          link_href = link.get('href')\n",
        "          if \"washingtonpost.com\" in link_href:\n",
        "            print(link_href)\n",
        "            link_urls_array.append(link_href)\n",
        "\n",
        "  # Count the number of internal links.\n",
        "  num_internal_links = len(link_urls_array)\n",
        "  print(\"num_internal_links: \" + str(num_internal_links))\n",
        "  # Calculate the average number of paragraphs per internal link.\n",
        "  avg_paragraphs_per_internal_link = paragraph_count / num_internal_links if (num_internal_links > 0) else 0\n",
        "\n",
        "  score = \"Red\"\n",
        "  if avg_paragraphs_per_internal_link <= 5:\n",
        "    score = \"Green\"\n",
        "  elif avg_paragraphs_per_internal_link <= 10:\n",
        "    score = \"Yellow\"\n",
        "\n",
        "  need_to_add = math.ceil( ( paragraph_count / 5 ) - num_internal_links )\n",
        "  print(\"need_to_add: \" + str(need_to_add))\n",
        "  valueObject = {'paragraph_count': paragraph_count, 'num_internal_links': num_internal_links, 'avg_paragraphs_per_internal_link': avg_paragraphs_per_internal_link, 'need_to_add': need_to_add }\n",
        "  print(\"valueObject: \")\n",
        "  print(valueObject)\n",
        "  return {'score': score, 'value': valueObject, 'suggestion': 'Ideally have 1 internal link per 5 paragraphs. You currently have 1 internal link per {} paragraphs.'.format(avg_paragraphs_per_internal_link)}\n",
        "\n",
        "def _analyze_recirc_links(story_object):\n",
        "  interstitial_array = []\n",
        "  carousel_array = []\n",
        "  paragraph_count = 0\n",
        "\n",
        "  for element in get_content_elements(story_object):\n",
        "    # print(element['type'])\n",
        "    if ( element['type'] == \"custom_embed\" and element['subtype'] == \"magnet\" and element['embed']['config']['subtype'] == \"collection\" ):\n",
        "      # print(\"Found story carousel\")\n",
        "      # print(element['subtype'])\n",
        "      # print(element['embed']['config']['subtype'])\n",
        "      carousel_array.append( { 'type': 'carousel', 'data': element['embed']['url'], 'title' : element['embed']['config']['title'] })\n",
        "\n",
        "    elif ( element['type'] == \"interstitial_link\" ):\n",
        "      interstitial_array.append( { 'type': 'interstitial', 'data': element['url'], 'title' : element['content']})\n",
        "      # print(element)\n",
        "    elif ( element['type'] == \"text\" ):\n",
        "      paragraph_count = paragraph_count + 1\n",
        "\n",
        "  num_recircs_links = len(interstitial_array) + len(carousel_array)\n",
        "\n",
        "  score = \"Red\"\n",
        "  if num_recircs_links >= 2:\n",
        "    score = \"Green\"\n",
        "  elif num_recircs_links == 1:\n",
        "    score = \"Yellow\"\n",
        "\n",
        "  need_to_add = max( [0, 2 - ( len(interstitial_array) + len(carousel_array) )]  )\n",
        "  return {'score': score, 'need_to_add': need_to_add, 'value': 'You currently have {} interstitials and {} story carousels for your {} paragraph story.'.format(len(interstitial_array), len(carousel_array), paragraph_count), 'suggestion': 'Ideally have at least 2 interstitials or story carousels for articles at least 12 paragraphs long.'}\n",
        "\n",
        "keywords = []\n",
        "def score_seo_keywords(this_ai_score_object, this_story_object):\n",
        "  global keywords\n",
        "  headline = get_story_headline(this_story_object),\n",
        "  title = get_story_title( this_story_object ),\n",
        "  description = get_story_description( this_story_object )\n",
        "  canonical_url = get_story_canonical_url( this_story_object )\n",
        "\n",
        "  keywords = ai_score_object['keywords']\n",
        "\n",
        "  headline_keyword_cnt = count_keywords(headline, keywords)\n",
        "  title_keyword_cnt = count_keywords(title, keywords)\n",
        "  description_keyword_cnt = count_keywords(description, keywords)\n",
        "  canonical_url_keyword_cnt = count_keywords(canonical_url, keywords)\n",
        "  print(\"canonical_url_keyword_cnt: \"+ str(canonical_url_keyword_cnt))\n",
        "  def score_by_cnt(xcount):\n",
        "    if xcount > 2:\n",
        "      return \"Green\", \"\"\n",
        "    elif xcount > 0:\n",
        "      return \"Yellow\", \"Add more SEO keywords.\"\n",
        "    return \"Red\", \"Add more SEO keywords.\"\n",
        "\n",
        "  this_ai_score_object['headline_score'], this_ai_score_object['headline_comment'] = score_by_cnt(headline_keyword_cnt)\n",
        "  this_ai_score_object['meta_title_score'], this_ai_score_object['meta_title_comment'] = score_by_cnt(title_keyword_cnt)\n",
        "  this_ai_score_object['meta_description_score'], this_ai_score_object['meta_description_comment'] = score_by_cnt(description_keyword_cnt)\n",
        "  this_ai_score_object['canonical_url_score'], this_ai_score_object['canonical_url_comment'] = score_by_cnt(canonical_url_keyword_cnt)\n",
        "\n",
        "\n",
        "  # return headline_keyword_cnt, title_keyword_cnt, description_keyword_cnt\n",
        "  # for item in ai_score_object['keywords']:\n",
        "  # count_keywords(string, keywords)\n",
        "\n",
        "  return this_ai_score_object\n",
        "\n",
        "\n",
        "\n",
        "# story_object = get_prism_data_from_url('https://www.washingtonpost.com/opinions/2023/10/17/jim-jordan-speaker-house-chaos/')\n",
        "# _analyze_recirc_links(story_object)\n",
        "\n",
        "# --- prism link of stories in collection / story carousel\n",
        "#     https://prism.wpit.nile.works/content/v4/collections?content_alias=opgaza\n",
        "\n",
        "# ----------------------- DATA FOR CAROUSEL\n",
        "# {'_id': 'MFNZXPFAWBEQNHU7VVPTHW7RVM',\n",
        "#  'additional_properties': {\n",
        "#     '_id': 'MMMHPOKNURAUDFMUIPC7IE3VG4'\n",
        "#   },\n",
        "#  'embed': {\n",
        "#     'config': {\n",
        "#         'cdn_url': 'https://prism.wpit.nile.works/content/v4/collections?content_alias=opgaza',\n",
        "#         'feed': 'opgaza',\n",
        "#         'subtype': 'collection',\n",
        "#         'title': 'Opinions on the Israel-Gaza war'},\n",
        "#     'id': 'opgaza',\n",
        "#     'url': 'https://prism.wpit.nile.works/content/v4/collections?content_alias=opgaza'\n",
        "#   },\n",
        "#  'subtype': 'magnet',\n",
        "#  'type': 'custom_embed'\n",
        "# }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHQV4tzZjMeR"
      },
      "outputs": [],
      "source": [
        "# @title Interface HTML Functions\n",
        "\n",
        "\n",
        "\n",
        "# ---- AI response:\n",
        "\n",
        "# {\n",
        "#     \"keywords\": [\n",
        "#         \"marijuana restrictions\",\n",
        "#         \"medical treatment\",\n",
        "#         \"marijuana reclassification\",\n",
        "#         \"Drug Enforcement Administration\",\n",
        "#         \"Veterans Cannabis Project\",\n",
        "#         \"cannabis companies\"\n",
        "#     ],\n",
        "#     \"headlines\": [\n",
        "#         \"Major Implications Expected as Marijuana Restrictions May Ease\",\n",
        "#         \"Health Agency Recommends Reclassification of Marijuana: A Step Towards National Legalization?\",\n",
        "#         \"Marijuana Reclassification Could Boost Cannabis Businesses and Medical Treatment\"\n",
        "#     ],\n",
        "#     \"meta_titles\": [\n",
        "#         \"Potential Easing of Marijuana Restrictions: What It Means\",\n",
        "#         \"Reclassification of Marijuana: A Game Changer for Medical Treatment and Cannabis Businesses\",\n",
        "#         \"Health Agency's Recommendation to Reclassify Marijuana: The Implications\"\n",
        "#     ],\n",
        "#     \"meta_descriptions\": [\n",
        "#         \"The nation's top health agency recommends reclassifying marijuana, potentially paving the way for wider acceptance as a medical treatment and boosting cannabis businesses.\",\n",
        "#         \"The possible reclassification of marijuana could have significant implications, including a potential path towards national legalization and increased scientific research into the drug's health benefits.\"\n",
        "#     ]\n",
        "# }\n",
        "\n",
        "\n",
        "# {'headline_score': 'Yellow',\n",
        "#  'headline_comment': 'The headline accurately describes the story, but it could be improved by including SEO keyword(s) for the story.',\n",
        "#  'canonical_url_score': 'Green',\n",
        "#  'canonical_url_comment': '',\n",
        "#  'meta_title_score': 'Yellow',\n",
        "#  'meta_title_comment': 'The meta title includes the SEO keyword(s) for the story, but it could be improved.',\n",
        "#  'meta_description_score': 'Yellow',\n",
        "#  'meta_description_comment': 'The meta description includes the SEO keyword(s) for the story, but it could be improved.'}\n",
        "\n",
        "\n",
        "\n",
        "def convert_score_object_to_html(score_object, reCircLinks, story_object, ai_score_object):\n",
        "  string_scores = [\"Green\", \"Yellow\", \"Red\"]\n",
        "  ai_like_it_html = '<span class=\"Green\">&#10004;</span><span style=\"margin-left:6px;\">Looks good!</span>'\n",
        "\n",
        "  # --------------------------------------------------------------------------------------------headline score\n",
        "  # headline_score = score_object['headline']['value']\n",
        "  # suggestion_text = \"<div class=''><strong>Suggestions:</strong> \" + score_object['headline']['suggestion'] + \"</div>\" if (score_object['headline']['suggestion'] != '' and score_object['headline']['score'] != 'Green') else ''\n",
        "  suggestion_text = \"<div class=''>\" + score_object['headline']['suggestion'] + \"</div>\"\n",
        "\n",
        "  # <span class=\"'+ score +'\">&#10060;</span>\n",
        "  # ---- ai scoring\n",
        "  headline_ai_suggestions = \"<div class=''><span class='\"+ ai_score_object['headline_score'] +\"' style='margin-right:6px;'>&#10008;</span><strong>Suggestion:</strong> \"+ ai_score_object['headline_comment'] if (ai_score_object['headline_comment'] != '' and ai_score_object['headline_score'] != 'Green') else ai_like_it_html\n",
        "  headline_html = \"\"\"\n",
        "    <li class=\"response_li li_{}\">\n",
        "      <h2>Headline</h2>\n",
        "      <div class=\"\">{}</div>\n",
        "      {}\n",
        "      {}\n",
        "    </li>\n",
        "  \"\"\".format(\n",
        "      max([ score_object['headline']['score'], ai_score_object['headline_score']], key=lambda x: string_scores.index(x)),\n",
        "      score_object['headline']['value'],\n",
        "      suggestion_text,\n",
        "      headline_ai_suggestions\n",
        "  )\n",
        "\n",
        "  # --------------------------------------------------------------------------------------------title score\n",
        "  # suggestion_text = \"<div class=''><strong>Suggestions:</strong> \" + score_object['title']['suggestion'] + \"</div>\" if (score_object['title']['suggestion'] != '' and score_object['title']['score'] != 'Green') else ''\n",
        "  suggestion_text = \"<div class=''>\" + score_object['title']['suggestion'] + \"</div>\"\n",
        "\n",
        "  title_ai_alt_suggestions = \"<h4 style='color: #a3a3a3;'>Alternate title suggestions:</h4><ul style='margin: 0px;font-size: 100%;margin-bottom:2px !important'>\"\n",
        "  for item in ai_score_object['meta_titles']:\n",
        "      title_ai_alt_suggestions += '<li class=\"response_li\" style=\"margin-bottom:2px !important\">' + item + ' ('+ str(len(item)) +' chars)</li>'\n",
        "  title_ai_alt_suggestions += \"</ul>\"\n",
        "\n",
        "\n",
        "  # ---- ai scoring\n",
        "  title_ai_suggestions = ''\n",
        "  title_current_html = ''\n",
        "  if score_object['title']['score_value'] > 0:\n",
        "    title_ai_suggestions = \"<div><span class='\"+ ai_score_object['meta_title_score'] +\"' style='margin-right:6px;'>&#10008;</span><strong>Suggestion:</strong> \"+ ai_score_object['meta_title_comment']+\"</div>\" if (ai_score_object['meta_title_comment'] != '' and ai_score_object['meta_title_score'] != 'Green') else ai_like_it_html\n",
        "    title_current_html = '<div><span class=\"\">'+ score_object['title']['value'] +'</span></div>'\n",
        "\n",
        "    # Suggestion: The meta title is missing. It should include primary keywords and accurately reflect the content of the story to improve SEO.\n",
        "\n",
        "\n",
        "  title_html = \"\"\"\n",
        "    <li class=\"response_li li_{}\">\n",
        "      <h2>Meta Title</h2>\n",
        "      {}\n",
        "      {}\n",
        "      {}\n",
        "      {}\n",
        "    </li>\n",
        "  \"\"\".format(\n",
        "      max([ score_object['title']['score'], ai_score_object['meta_title_score']], key=lambda x: string_scores.index(x)),\n",
        "      title_current_html,\n",
        "      suggestion_text,\n",
        "      title_ai_suggestions,\n",
        "      title_ai_alt_suggestions\n",
        "  )\n",
        "\n",
        "  # --------------------------------------------------------------------------------------------description score\n",
        "  # suggestion_text = \"<div class=''><strong>Suggestions:</strong> \" + score_object['meta_description']['suggestion'] + \"</div>\" if (score_object['meta_description']['suggestion'] != '' and score_object['meta_description']['score'] != 'Green') else ai_like_it_html\n",
        "  suggestion_text = \"<div class=''>\" + score_object['meta_description']['suggestion'] + \"</div>\"\n",
        "\n",
        "  description_ai_alt_suggestions = \"<h4 style='color: #a3a3a3;'>Alternate description suggestions:</h4><ul style='margin: 0px;font-size: 100%;margin-bottom:2px !important'>\"\n",
        "  for item in ai_score_object['meta_descriptions']:\n",
        "      description_ai_alt_suggestions += '<li class=\"response_li\" style=\"margin-bottom:2px !important\">' + item + ' ('+ str(len(item)) +' chars)</li>'\n",
        "  description_ai_alt_suggestions += \"</ul>\"\n",
        "\n",
        "  description_ai_suggestions = \"\"\n",
        "  if \"meta_description_score\" in ai_score_object:\n",
        "    description_ai_suggestions = \"<div class=''><span class='\"+ ai_score_object['meta_description_score'] +\"' style='margin-right:6px;'>&#10008;</span><strong>Suggestion:</strong> \"+ ai_score_object['meta_description_comment'] if (ai_score_object['meta_description_comment'] != '' and ai_score_object['meta_description_score'] != 'Green') else ai_like_it_html\n",
        "\n",
        "    description_html = \"\"\"\n",
        "      <li class=\"response_li li_{}\">\n",
        "        <h2>Meta Description</h2>\n",
        "        <div class=\"\"><strong>Current:</strong> {}</div>\n",
        "        {}\n",
        "        {}\n",
        "        {}\n",
        "      </li>\n",
        "    \"\"\".format(\n",
        "        max([ score_object['meta_description']['score'], ai_score_object['meta_description_score']], key=lambda x: string_scores.index(x)),\n",
        "        score_object['meta_description']['value'],\n",
        "        suggestion_text,\n",
        "        description_ai_suggestions,\n",
        "        description_ai_alt_suggestions\n",
        "    )\n",
        "\n",
        "\n",
        "  # --------------------------------------------------------------------------------------------canonical url score\n",
        "  # ---- ai scoring\n",
        "  canon_ai_suggestions = \"<div class=''><span class='\"+ ai_score_object['canonical_url_score'] +\"' style='margin-right:6px;'>&#10008;</span><strong>Suggestion:</strong> \"+  ai_score_object['canonical_url_comment'] if (ai_score_object['canonical_url_comment'] != '' and ai_score_object['canonical_url_score'] != 'Green') else ai_like_it_html\n",
        "\n",
        "  canon_ai_html = \"\"\"\n",
        "    <li class=\"response_li li_{}\">\n",
        "      <h2>Custom Url</h2>\n",
        "      <div class=\"\">Current: {}</div>\n",
        "      {}\n",
        "    </li>\n",
        "  \"\"\".format(\n",
        "      ai_score_object['canonical_url_score'],\n",
        "      get_story_canonical_url(story_object),\n",
        "      canon_ai_suggestions\n",
        "  )\n",
        "\n",
        "  # --------------------------------------------------------------------------------------------reCirc score\n",
        "  # print( score_object['recirc_links'] )\n",
        "  # suggestion_text = \"<div class=''><strong>Suggestions:</strong> \" + score_object['recirc_links']['suggestion'] + \"</div>\" if (score_object['recirc_links']['suggestion'] != '') else ''\n",
        "  suggestion_text = \"<div class=''><strong>Suggestions:</strong> \" + score_object['recirc_links']['suggestion'] + \"</div>\" if (score_object['recirc_links']['suggestion'] != '' and score_object['recirc_links']['score'] != 'Green') else ai_like_it_html\n",
        "  recirc_links_html = ''\n",
        "\n",
        "  recirc_suggest = \"\"\n",
        "  if ( score_object['recirc_links']['need_to_add'] > 0):\n",
        "    recirc_suggest = '<div><span class=\"{}\">&#10008;</span><strong style=\"margin-left:6px;\">Add:</strong> {} interstitials or story carousels</div>'.format(\n",
        "        score_object['recirc_links']['score'],\n",
        "        score_object['recirc_links']['need_to_add']\n",
        "    )\n",
        "\n",
        "  if len(reCircLinks) > 0:\n",
        "    recirc_links_html = \"<div style='margin-top:8px;'><strong>Suggested in-line links to include:</strong></div>\"\n",
        "    for recirc_link in reCircLinks:\n",
        "      recirc_links_html += \"<a href='https://www.washingtonpost.com\"+ recirc_link['canonUrl'] +\"' target='_blank'>\"+ recirc_link['headline'] +\"</a></BR>\"\n",
        "\n",
        "  recirc_html = \"\"\"\n",
        "    <li class=\"response_li li_{}\">\n",
        "      <h2>ReCirc Links</h2>\n",
        "      {}\n",
        "      <div class=\"\">{}</div>\n",
        "      {}\n",
        "    </li>\n",
        "  \"\"\".format(\n",
        "      score_object['recirc_links']['score'],\n",
        "      recirc_suggest,\n",
        "      score_object['recirc_links']['value'],\n",
        "      suggestion_text\n",
        "  )\n",
        "\n",
        "  # --------------------------------------------------------------------------------------------Internal Links score\n",
        "  internal_links_html = \"<div>ERROR</div>\"\n",
        "  try:\n",
        "    suggestion_text = \"<div class=''><strong>Suggestions:</strong> \" + score_object['internal_links']['suggestion'] + \"</div>\" if (score_object['internal_links']['suggestion'] != '' and score_object['internal_links']['score'] != 'Green') else ai_like_it_html\n",
        "\n",
        "    internal_links_suggest = \"\"\n",
        "    if ( score_object['internal_links']['score'] != \"Green\" and score_object['internal_links']['value']['need_to_add'] > 0):\n",
        "      internal_links_suggest = '<div><span class=\"{}\">&#10008;</span><strong style=\"margin-left:6px;\">Add:</strong> {} links</div>'.format(\n",
        "          score_object['internal_links']['score'],\n",
        "          score_object['internal_links']['value']['need_to_add']\n",
        "      )\n",
        "\n",
        "    # <div class=\"\"><strong>Paragraphs:</strong> {}</div>\n",
        "    # <div class=\"\"><strong>Internal Links:</strong> {}</div>\n",
        "    # <div class=\"\"><strong>Paragraphs per Internal Link:</strong> {}</div>\n",
        "\n",
        "    # print(json.dumps(score_object, indent=2))\n",
        "    internal_links_html = \"\"\"\n",
        "      <li class=\"response_li li_{}\">\n",
        "        <h2>Internal Links</h2>\n",
        "        {}\n",
        "        {}\n",
        "        {}\n",
        "      </li>\n",
        "    \"\"\".format(\n",
        "        score_object['internal_links']['score'],\n",
        "        internal_links_suggest,\n",
        "        # score_object['internal_links']['value']['paragraph_count'],\n",
        "        # score_object['internal_links']['value']['num_internal_links'],\n",
        "        # score_object['internal_links']['value']['avg_paragraphs_per_internal_link'],\n",
        "        suggestion_text,\n",
        "        recirc_links_html\n",
        "    )\n",
        "  except KeyError as e:\n",
        "    print(\"ERROR\")\n",
        "    print(e)\n",
        "    internal_links_html = \"***** Error: \" #+ str(e)\n",
        "\n",
        "  # --------------------------------------------------------------------------------------------Keywords\n",
        "\n",
        "  ai_keywords_html = \"\" #\"<ul>\"\n",
        "  for item in ai_score_object['keywords']:\n",
        "      # ai_keywords_html += '<li style=\"margin-bottom:2px !important\">' + item + '</li>'\n",
        "      ai_keywords_html += '<div class=\"keyword_box\">' + item + '</div>'\n",
        "\n",
        "  keywords_text = \"\"\"\n",
        "\n",
        "    <li class=\"response_li\" style=\"display: inline-block;\"><h2>Keywords</h2>\n",
        "    {}</li>\n",
        "  \"\"\".format(\n",
        "      ai_keywords_html,\n",
        "      # non_ai_keywords_html\n",
        "  )\n",
        "\n",
        "\n",
        "  styles = \"\"\"\n",
        "  <style>\n",
        "      .keyword_box {\n",
        "          padding: 10px;\n",
        "          width: max-content;\n",
        "          min-width: 127px;\n",
        "          float: left;\n",
        "          text-align: center;\n",
        "          margin-right: 10px;\n",
        "          background-color: #e5e7eb;\n",
        "          font-weight: bold;\n",
        "          line-height: normal;\n",
        "          margin-bottom: 10px;\n",
        "      }\n",
        "      .Green {\n",
        "        color: #27ae60 !important;\n",
        "      }\n",
        "      .Yellow {\n",
        "        color: #f1c40f !important;\n",
        "      }\n",
        "      .Red {\n",
        "        color: #e74c3c !important;\n",
        "      }\n",
        "      .xtrot {\n",
        "        float:left !important;\n",
        "        margin-right:20px !important;\n",
        "\n",
        "      }\n",
        "      .response_ul {\n",
        "        list-style: none !important;\n",
        "\n",
        "      }\n",
        "      .response_li {\n",
        "\n",
        "        line-height:23px !important;\n",
        "        margin-left: 20px;\n",
        "        padding-left: 7px;\n",
        "        list-style-type: circle;\n",
        "      }\n",
        "      .li_Green {\n",
        "        list-style-type: \"✔\" !important;\n",
        "        color: #27ae60 !important;\n",
        "      }\n",
        "      .li_Red {\n",
        "        list-style-type: \"✘\" !important;\n",
        "        color: #e74c3c !important;\n",
        "      }\n",
        "      .li_Yellow {\n",
        "        list-style-type: \"✘\" !important;\n",
        "        color: #f1c40f !important;\n",
        "      }\n",
        "      .container_div {\n",
        "        font-size: 100%;\n",
        "        margin-bottom: 50px;\n",
        "      }\n",
        "  </style>\n",
        "  \"\"\"\n",
        "\n",
        "  html = \"\"\"\n",
        "  <div class=\"container_div\">\n",
        "    {}\n",
        "    <ul class=\"response_ul\">\n",
        "    {}\n",
        "    {}\n",
        "    {}\n",
        "    {}\n",
        "    {}\n",
        "    {}\n",
        "    {}\n",
        "    </ul>\n",
        "  </div>\n",
        "  \"\"\".format(\n",
        "      styles,\n",
        "      keywords_text,\n",
        "      headline_html,\n",
        "      title_html,\n",
        "      description_html,\n",
        "      canon_ai_html,\n",
        "      internal_links_html,\n",
        "      recirc_html,\n",
        "  )\n",
        "\n",
        "  return html\n",
        "\n",
        "# NOT using this funciton anymore... (replaced by convert_score_object_to_html)\n",
        "#    Keeping for reference\n",
        "def render_results(score_object):\n",
        "  \"\"\"Renders the results of the analyze_seo_by_url function in HTML.\n",
        "  Args: score_object: The score object returned by the analyze_seo_by_url function.\n",
        "  Returns: An HTML string containing the results.\"\"\"\n",
        "\n",
        "  # print(score_object)\n",
        "\n",
        "  headline_score = score_object['headline']['score']\n",
        "\n",
        "\n",
        "\n",
        "  html = \"\"\"\n",
        "  <html>\n",
        "  <head>\n",
        "  <title>SEO Score</title>\n",
        "  </head>\n",
        "  <body>\n",
        "  <h1>SEO Score</h1>\n",
        "  <p>Your website's SEO score is XXXXX.</p>\n",
        "  <p>The following are the individual scores for each category:</p>\n",
        "  <ul>\n",
        "  <li>Headline: ({} chars) {}</li>\n",
        "  <li>Internal Links: ({} paragraphs per link) {}</li>\n",
        "  <li>Recirc Links: ({}) {}</li>\n",
        "  <li>Meta description: ({} chars) {}</li>\n",
        "\n",
        "  </ul>\n",
        "  </body>\n",
        "  </html>\n",
        "  \"\"\".format(\n",
        "      score_object['headline']['value'],\n",
        "      score_object['headline']['score'],\n",
        "      score_object['internal_links']['value'],\n",
        "      score_object['internal_links']['score'],\n",
        "      score_object['recirc_links']['value'],\n",
        "      score_object['recirc_links']['score'],\n",
        "      score_object['meta_description']['value'],\n",
        "      score_object['meta_description']['score'])\n",
        "  return html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNDGQ88HPwdC"
      },
      "outputs": [],
      "source": [
        "# @title Story data functions (non-AI : keywords, etc.)\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "TextBlob_model = KeyBERT()\n",
        "\n",
        "def get_keywords_from_story_object(story_object):\n",
        "  story_text = get_full_story_story_object(story_object)\n",
        "  # print(story_text)\n",
        "  # --------------test using KeyBERT\n",
        "  # keybert_keywords = TextBlob_model.extract_keywords(story_text)\n",
        "\n",
        "  # return TextBlob_model.extract_keywords(story_text, highlight=True)\n",
        "  # keybert_keywords = TextBlob_model.extract_keywords(story_text, keyphrase_ngram_range=(1, 3), highlight=True)\n",
        "  # print( \"keybert:\" + keybert_keywords)\n",
        "\n",
        "  headline_text = get_story_headline( story_object )\n",
        "  meta_title_text = get_story_title( story_object )\n",
        "  description_text( story_object )\n",
        "\n",
        "  fullstring = headline_text + '. ' + story_text\n",
        "  keybert_keywords = get_keywords_from_string(fullstring)\n",
        "\n",
        "  # blob = TextBlob(headline_text)\n",
        "  # print(blob.noun_phrases)\n",
        "\n",
        "  # textblob_nouns = [w for (w, pos) in TextBlob(headline_text).pos_tags if pos[0] == 'N']\n",
        "  # print( \"textblob_nouns:\" + textblob_nouns)\n",
        "\n",
        "\n",
        "  df = pd.DataFrame(keybert_keywords)\n",
        "  df = df.loc[df[1] > 0.3]    # gets rid of keywords with score lower than .3\n",
        "  df = remove_similar_words_df(df)\n",
        "\n",
        "  keyword_array = []\n",
        "  for index, row in df.iterrows():\n",
        "    keyword_array.append(row[0])\n",
        "\n",
        "\n",
        "  return keyword_array\n",
        "\n",
        "  # for rating, keyword in r.get_ranked_phrases_with_scores():\n",
        "  #   if rating > 5:\n",
        "  #       print(rating, keyword)\n",
        "\n",
        "  # return r.get_ranked_phrases_with_scores()\n",
        "  # return r.get_word_degrees()\n",
        "  # return r.get_word_frequency_distribution()\n",
        "  # return r.extract_keywords_from_text(story_text)\n",
        "\n",
        "# story_object = get_prism_data_from_url('https://www.washingtonpost.com/sports/2023/10/01/taylor-swift-kelce-chiefs-jets/')\n",
        "# # get_keywords(story_object)\n",
        "# story_html_string = get_keywords(story_object)\n",
        "\n",
        "def get_keywords_from_string(mystring):\n",
        "  return TextBlob_model.extract_keywords(mystring)\n",
        "\n",
        "def get_noun_phrases_from_string(mystring):\n",
        "  blob = TextBlob(mystring)\n",
        "  return blob.noun_phrases\n",
        "\n",
        "def get_word_counts_from_string(needle, haystack):\n",
        "  return haystack.word_counts[needle]\n",
        "\n",
        "\n",
        "\n",
        "import difflib\n",
        "\n",
        "# def remove_similar_words_df(df):\n",
        "#   # Get the first column of the dataframe.\n",
        "#   first_column = df.iloc[:, 0]\n",
        "\n",
        "#   # Create a list of words that are longer than 10 letters.\n",
        "#   long_words = [word for word in first_column if len(word) > 10]\n",
        "\n",
        "#   # Remove the rows that contain any of the long words.\n",
        "#   df = df[~df.iloc[:, 0].isin(long_words)]\n",
        "\n",
        "#   return df\n",
        "\n",
        "\n",
        "# word_list = ['frog', 'toad', 'legalize', 'legalization', 'legalized']\n",
        "# # word_list = ['marijuana', 'cannabis', 'weed']\n",
        "# close_match = difflib.get_close_matches('legalize', word_list)\n",
        "# # print( close_match)\n",
        "# close_match.remove('legalize')\n",
        "\n",
        "# result = []\n",
        "# for i in word_list:\n",
        "#     if i not in close_match:\n",
        "#         result.append(i)\n",
        "# # print(result)\n",
        "\n",
        "# # >>> ['asf', 'bcd', 'cdf']\n",
        "\n",
        "\n",
        "# def remove_similar_words_df(df):\n",
        "#   xlist = df.values[:, 0]\n",
        "#   new_array = []\n",
        "\n",
        "from difflib import get_close_matches\n",
        "\n",
        "# xlist = ['frog', 'toad', 'legalize', 'legalization', 'legalized', 'cat']\n",
        "# xlist = keywords.values[:, 0].tolist()\n",
        "# new_array = []\n",
        "\n",
        "# while xlist:\n",
        "#     word = xlist.pop()\n",
        "#     new_array.append(word)\n",
        "#     xlist = [x for x in xlist if x not in get_close_matches(word, xlist, cutoff=0.6)]\n",
        "\n",
        "# print(new_array)\n",
        "\n",
        "# df = keywords[~keywords[0].isin(new_array)]\n",
        "# print(df)\n",
        "\n",
        "def remove_similar_words_df(df):\n",
        "  xlist = df.values[:, 0].tolist()\n",
        "  new_array = []\n",
        "\n",
        "  while len(xlist) > 0:\n",
        "    word = xlist.pop()\n",
        "    new_array.append(word)\n",
        "    xlist = [x for x in xlist if x not in get_close_matches(word, xlist, cutoff=0.8)]\n",
        "\n",
        "  # print( new_array)\n",
        "  # if not new_array:\n",
        "  #   return df\n",
        "\n",
        "  # df = df[~df[0].isin(new_array)]\n",
        "  new_df = df[df[0].isin(new_array)]\n",
        "  return new_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJ34sGPQNsrK"
      },
      "outputs": [],
      "source": [
        "# @title 3rd party API functions (non-AI: content_API, ReCirc tool, etc)\n",
        "\n",
        "def get_content_from_content_elements(content_elements, headline = '', keep_html = False):\n",
        "  full_story = [headline] if headline != '' else []\n",
        "  for element in content_elements:\n",
        "    if element['type'] == 'text':\n",
        "      full_story.append(element['content'])\n",
        "\n",
        "  soup = BeautifulSoup(\"\".join(str(x) for x in full_story))\n",
        "  full_text = soup.get_text() if keep_html != True else soup.html\n",
        "\n",
        "  return full_text\n",
        "\n",
        "# def get_full_story_from_search_results(search_object, add_headline = True):\n",
        "\n",
        "\n",
        "\n",
        "def get_full_story_story_object(story_object, add_headline = True):\n",
        "  # print( 'get_full_story_story_object' )\n",
        "  # print( story_object )\n",
        "\n",
        "  headline = get_story_headline( story_object )+'. ' if add_headline else ''\n",
        "  return get_content_from_content_elements(get_content_elements(story_object), headline, True)\n",
        "\n",
        "def get_full_story_html_api(story_object, add_headline = True ):\n",
        "  headline = '<h1>' + get_story_headline( story_object ) + '</h1>' if add_headline else ''\n",
        "  return get_content_from_content_elements(get_content_elements(story_object), headline)\n",
        "\n",
        "def get_recirc_links_from_storyObject(story_object):\n",
        "  headline = get_story_headline( story_object )\n",
        "  section_url = get_story_section_path( story_object)\n",
        "  canon_url = get_story_canonical_url( story_object)\n",
        "  return get_recirc_links_from_ai(headline, section_url, canon_url)\n",
        "\n",
        "def get_recirc_links_from_ai(headline, section, url):\n",
        "  api_url = \"https://{url}/api/wp-rec-articles/\"\n",
        "  url = url.replace('https://www.washingtonpost.com', '')\n",
        "  payload = json.dumps({\n",
        "    \"input\": {\n",
        "      \"text\": headline,\n",
        "      \"topic\": section,\n",
        "      \"url\": url\n",
        "      # \"/elections/2023/09/20/trump-abortion-republicans-presidential/\"\n",
        "    }\n",
        "  })\n",
        "\n",
        "  # print( 'get_recirc_links_from_ai' )\n",
        "  # print( payload )\n",
        "\n",
        "  headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': 'Bearer ',\n",
        "    'Cookie': 'connect.sid='\n",
        "  }\n",
        "\n",
        "  try:\n",
        "    response = requests.request(\"POST\", api_url, headers=headers, data=payload)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    response_object = json.loads(response.json())\n",
        "\n",
        "    # formatted_array = []\n",
        "    # for story in response_object:\n",
        "\n",
        "    # print(response.text)\n",
        "\n",
        "    formatted_array = []\n",
        "    for story in response_object:\n",
        "      storyId = story['DocumentId']\n",
        "      headline = story['DocumentTitle']['Text']\n",
        "      pubDate = story['DocumentAttributes'][3]['Value']['StringValue']\n",
        "      canonUrl = story['DocumentAttributes'][4]['Value']['StringValue']\n",
        "      artType  = story['DocumentAttributes'][5]['Value']['StringValue']\n",
        "      taxonomy = story['DocumentAttributes'][7]['Value']['StringListValue']\n",
        "\n",
        "      answerText = story['DocumentExcerpt']['Text']\n",
        "      excerpt = story['DocumentExcerpt']['Text']\n",
        "      score = story['ScoreAttributes']['ScoreConfidence']\n",
        "\n",
        "      # answerText = story['AdditionalAttributes']    # not all stories have this\n",
        "      # print(headline)\n",
        "      formatted_array.append( {\n",
        "          \"storyId\": storyId ,\n",
        "          \"headline\": headline,\n",
        "          \"pubDate\": pubDate,\n",
        "          \"canonUrl\": canonUrl,\n",
        "          \"artType\": artType,\n",
        "          \"taxonomy\": taxonomy,\n",
        "          \"answerText\": answerText,\n",
        "          \"excerpt\": excerpt,\n",
        "          \"score\": score })\n",
        "\n",
        "    return formatted_array\n",
        "\n",
        "  except requests.exceptions.HTTPError as err:\n",
        "    print(\" ERROR LOADING RECIRC LINK ------\")\n",
        "    print( response )\n",
        "\n",
        "    # raise SystemExit(err)\n",
        "\n",
        "  # response = requests.request(\"POST\", api_url, headers=headers, data=payload)\n",
        "  # print( response )\n",
        "\n",
        "  return []\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7ggyu1oVOT_"
      },
      "outputs": [],
      "source": [
        "# @title PyTrend Functions!!!\n",
        "\n",
        "# from: https://colab.research.google.com/github/FrontAnalyticsInc/data-winners/blob/main/analysis-trends/trends-and-forecasts.ipynb#scrollTo=c02a85f6\n",
        "\n",
        "#install pytrends\n",
        "\n",
        "\n",
        "#import the libraries\n",
        "import pandas as pd\n",
        "from pytrends.request import TrendReq\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# use custom header\n",
        "requests_args = {\n",
        "    'headers': {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# --- code 2\n",
        "# this caused errors occasionaly\n",
        "# pytrend = TrendReq(requests_args=requests_args)\n",
        "\n",
        "pytrends = TrendReq(hl='en-US', tz=360, timeout=(10,25), retries=3, backoff_factor=0.3, requests_args={'verify':False})\n",
        "pytrend = TrendReq()\n",
        "\n",
        "#build model\n",
        "# pytrend = TrendReq(requests_args=requests_args)\n",
        "\n",
        "#provide your search terms\n",
        "# kw_list=['\"marijuana\"']\n",
        "# kw_list=['\"marijuana\"']\n",
        "# pytrend.build_payload(kw_list=kw_list)\n",
        "# pytrend.build_payload(kw_list=['pizza', 'bagel'], timeframe=['2022-09-04 2022-09-10', '2022-09-18 2022-09-24']))\n",
        "# pytrend.get_historical_interest(kw_list, year_start=2018, month_start=1, day_start=1, hour_start=0, year_end=2018, month_end=2, day_end=1, hour_end=0, cat=0, geo='', gprop='', sleep=0)\n",
        "# pytrend.build_payload(kw_list, cat=0, timeframe='today 5-y', geo='', gprop='')\n",
        "\n",
        "# kw_list = [\"Blockchain\"]\n",
        "# pytrend.build_payload(kw_list, cat=0, timeframe='today 5-y', geo='', gprop='')\n",
        "\n",
        "#---------------------------get related queries (CJ NOT BAD)\n",
        "# related_queries = pytrend.related_queries()\n",
        "# related_queries.values()\n",
        "# #build lists dataframes\n",
        "# top = list(related_queries.values())[0]['top']\n",
        "\n",
        "\n",
        "# rising = list(related_queries.values())[0]['rising']  #this has queries that will contain the word in it\n",
        "\n",
        "#convert lists to dataframes\n",
        "# dftop = pd.DataFrame(top)\n",
        "# dfrising = pd.DataFrame(rising)\n",
        "\n",
        "# dftop.head(50)\n",
        "\n",
        "\n",
        "def gtrends_get_related_queries(query_array):\n",
        "  # pytrend.build_payload(kw_list=['weed', 'marijuana', 'cannabis'], geo='US', gprop='', timeframe='now 1-H') today 1-m\n",
        "  pytrend.build_payload(kw_list=query_array, geo='US', gprop='', timeframe='now 1-H')\n",
        "  # pytrend.build_payload(kw_list=query_array, timeframe='today 5-y', geo='US', gprop='')\n",
        "\n",
        "  related_queries = pytrend.related_queries()\n",
        "  related_queries.values()\n",
        "  top = list(related_queries.values())[0]['top']\n",
        "\n",
        "  return pd.DataFrame(top)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def gtrends_get_suggestions(query_string):\n",
        "  return pd.DataFrame(pytrend.suggestions(query_string))\n",
        "\n",
        "# print( gtrends_get_related_queries([\"marijuana restrictions\"]) )\n",
        "# print( gtrends_get_suggestions(\"marijuana restrictions\") )\n",
        "\n",
        "#get today's treniding topics\n",
        "# trendingtoday = pytrend.today_searches(pn='US')\n",
        "\n",
        "# Get Google Top Charts\n",
        "# for querystring in trendingtoday:\n",
        "#     q = querystring.split(\"q=\")[1].split(\"&\")[0].replace(\"+\",\" \")\n",
        "#     print(q)\n",
        "\n",
        "    #prints something like this\n",
        "    # Pittsburgh Steelers\n",
        "    # Pakistan vs Afghanistan\n",
        "    # John Stamos\n",
        "    # Liz Cheney\n",
        "\n",
        "\n",
        "\n",
        "# --- code 3\n",
        "\n",
        "def gtrends_get_interest_over_time(query_array, timeframe = 'today 1-m'):\n",
        "  # 'now 1-H'\n",
        "  pytrend.build_payload(kw_list=query_array, geo='US', gprop='', timeframe=timeframe)\n",
        "  return pytrend.interest_over_time()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# pytrend.related_queries()\n",
        "# pytrend.related_topics()\n",
        "# pytrend.trending_searches(pn='united_states')\n",
        "# pytrend.realtime_trending_searches(pn='US')\n",
        "# pytrend.suggestions(\"marijuana\")\n",
        "\n",
        "\n",
        "# try:\n",
        "#   print(x)\n",
        "# except:\n",
        "#   print(\"An exception occurred\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYV9GEcgbOvZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title date functions\n",
        "\n",
        "# keywords[:5]\n",
        "# print( gtrends_get_related_queries(keywords[:5]) )\n",
        "# gtrends_get_related_queries(['hurricane'])\n",
        "# gtrends_get_related_queries(['Republican debate', 'Ron DeSantis', 'GOP presidential nomination', 'Donald Trump', 'Nikki Haley', 'Iowa caucuses'])\n",
        "# print( type(keywords) )\n",
        "# print( type(['marijuana', 'cannabis']) )\n",
        "\n",
        "# pytrend.build_payload(kw_list=['hurricane'], geo='US', gprop='', timeframe='now 1-d')\n",
        "# # pytrend.build_payload(kw_list=query_array, timeframe='today 5-y', geo='US', gprop='')\n",
        "\n",
        "# related_queries = pytrend.related_queries()\n",
        "# related_queries.values()\n",
        "# print(related_queries)\n",
        "# top = list(related_queries.values())[0]['top']\n",
        "# pd.DataFrame(top)\n",
        "import datetime\n",
        "from datetime import date\n",
        "from calendar import monthrange\n",
        "# pytrend.build_payload(kw_list=['hurricane', 'Winter storm'], geo='US', gprop='', timeframe='now 1-d')\n",
        "# pytrend.multirange_interest_over_time()\n",
        "def get_last_date_of_month(year: int, month: int) -> date:\n",
        "    \"\"\"Given a year and a month returns an instance of the date class\n",
        "    containing the last day of the corresponding month.\n",
        "\n",
        "    Source: https://stackoverflow.com/questions/42950/get-last-day-of-the-month-in-python\n",
        "    \"\"\"\n",
        "    return date(year, month, monthrange(year, month)[1])\n",
        "\n",
        "def convert_dates_to_timeframe(start: date, stop: date) -> str:\n",
        "    \"\"\"Given two dates, returns a stringified version of the interval between\n",
        "    the two dates which is used to retrieve data for a specific time frame\n",
        "    from Google Trends.\n",
        "    \"\"\"\n",
        "    return f\"{start.strftime('%Y-%m-%d')} {stop.strftime('%Y-%m-%d')}\"\n",
        "\n",
        "# start_date = date(2023, 12, 1)\n",
        "# stop_date = get_last_date_of_month(2023, 12)\n",
        "\n",
        "# print(convert_dates_to_timeframe(start_date, stop_date) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCdOUcgW3bzi",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title AI QUERY : ai_score_story() FUNCTION\n",
        "# string\n",
        "# number\n",
        "# boolean\n",
        "# null/empty\n",
        "# object\n",
        "# array\n",
        "\n",
        "def ai_score_story(story_object, story_html_string):\n",
        "  global open_ai_model, open_ai_max_tokens, open_ai_temp\n",
        "  seo_custom_functions = [\n",
        "      {\n",
        "          'name': 'analyze_story_seo',\n",
        "          'description': 'Analyze and score the SEO quality of parts of the story from the input text',\n",
        "          'parameters': {\n",
        "              'type': 'object',\n",
        "              'properties': {\n",
        "                  'keywords': {\n",
        "                      'type': 'string',\n",
        "                      'description': 'List of top 10 SEO keywords from story, separated by commas, in order of importance.'\n",
        "                  },\n",
        "                  'meta_titles': {\n",
        "                      'type': 'string',\n",
        "                      'description': 'Write 3 different meta titles for the story using the top SEO keywords when able, separated by **.'\n",
        "                  },\n",
        "                  'meta_description_score': {\n",
        "                      'type': 'string',\n",
        "                      \"enum\": [\"Green\", \"Yellow\", \"Red\"],\n",
        "                      'description': 'Does the meta description accurately describe the story?'\n",
        "                  },\n",
        "                  'meta_description_comment': {\n",
        "                      'type': 'string',\n",
        "                      'description': 'Add any suggestions to improve meta description.'\n",
        "                  },\n",
        "                  'meta_description_examples': {\n",
        "                      'type': 'string',\n",
        "                      'description': 'Write 3 different meta descriptions, each around 150 characters in length, using many top SEO keywords, separated by **.'\n",
        "                  }\n",
        "              },\n",
        "              \"required\": [\n",
        "                  \"keywords\",\n",
        "                  \"meta_titles\",\n",
        "                  \"meta_description_score\",\n",
        "                  \"meta_description_comment\",\n",
        "                  \"meta_description_examples\"\n",
        "              ]\n",
        "          }\n",
        "      }\n",
        "  ]\n",
        "  # print(\"Meta title: \")\n",
        "  # print(get_story_title( story_object ))\n",
        "  prompt = \"\"\"\n",
        "  Headline: {}\n",
        "  Story:\n",
        "  {}\n",
        "  Meta Title: {}\n",
        "  Meta Description: {}\n",
        "\n",
        "  Answer the following:\n",
        "  1. What are the TOP 10 SEO keywords for the story?\n",
        "  2. Write 3 meta titles, separated by **. Each should be:\n",
        "    - 50-60 characters in length. IMPORTANT!\n",
        "    - Use top SEO keywords as early in meta title as possible\n",
        "  3. SCORE the meta description according to scale of \"Red\" = Very good, \"Yellow\" = Needs work\n",
        "      and \"Red\" = Needs improvement.\n",
        "  4. Offer a suggestion on how to improve meta description.\n",
        "  5. Write 3 meta descriptions, around 150 characters in length, separated by **. Each should be:\n",
        "    - Different from the current description, headline or title\n",
        "    - Use as many top SEO keywords as possible\n",
        "    - Be clear and concise: What’s the story about?\n",
        "\n",
        "  IMPORTANT: Make the descriptions each around 150 characters in length.\n",
        "\n",
        "  At the end of the conversation, respond with \"<|DONE|>\".\"\"\".format(\n",
        "      get_story_headline(story_object),\n",
        "      story_html_string,\n",
        "      get_story_title( story_object ),\n",
        "      get_story_description( story_object )\n",
        "  )\n",
        "\n",
        "  try:\n",
        "    response = openai.chat.completions.create(\n",
        "        # model=\"gpt-3.5-turbo\",\n",
        "        # model=\"gpt-4\",\n",
        "        # model=\"gpt-3.5-turbo-16k\",\n",
        "        model=\"gpt-4-1106-preview\",\n",
        "        # model=open_ai_model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful but meticulous news copy editor, writer and SEO expert.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        functions = seo_custom_functions,\n",
        "        function_call = 'auto',\n",
        "        temperature=open_ai_temp,\n",
        "        # max_tokens=open_ai_max_tokens,\n",
        "    )\n",
        "\n",
        "    print('------------AI response')\n",
        "    print(response)\n",
        "    response_json = json.loads(response.choices[0].message.function_call.arguments)\n",
        "    print(response_json)\n",
        "    response_keywords = response_json['keywords'].split(', ')\n",
        "    response_meta_descriptions = response_json['meta_description_examples'].split('**')\n",
        "    response_meta_titles = response_json['meta_titles'].split('**')\n",
        "    print(\"meta 1\")\n",
        "    response_json['keywords'] = [s.strip() for s in response_keywords]\n",
        "    response_json['meta_descriptions'] = [s.strip() for s in response_meta_descriptions][:3]\n",
        "    response_json['meta_titles'] = [s.strip() for s in response_meta_titles][:3]\n",
        "    print(\"meta 2\")\n",
        "    return response_json\n",
        "\n",
        "  except openai.APIError as e:\n",
        "    #Handle API error here, e.g. retry or log\n",
        "    print(f\"----ERROR: OpenAI API returned an API Error: {e}\")\n",
        "    # return json of error\n",
        "    return { 'error': e }\n",
        "    pass\n",
        "\n",
        "  return {}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title quicktests -\n",
        "\n",
        "import IPython\n",
        "\n",
        "# url = \"https://www.washingtonpost.com/health/2023/12/21/colon-cancer-increasing-young-adults/\"\n",
        "url = \"https://www.washingtonpost.com/politics/2023/12/27/michigan-supreme-court-trump-2024-primary-ballot/\"\n",
        "\n",
        "# story_object = get_prism_data_from_url(url)\n",
        "# story_object\n",
        "\n",
        "# get_story_title(story_object)\n",
        "# get_story_canonical_url(story_object)\n",
        "\n",
        "# get_prism_search_data_by_query('taylor swift')\n",
        "\n",
        "# score_html = get_html_score_from_url( url )\n",
        "# IPython.display.HTML(score_html)\n",
        "\n",
        "# interface_search_stories_by_query(\"Lewiston\")\n",
        "\n",
        "# _analyze_title(story_object)\n",
        "\n",
        "# score_object, this_story_object = analyze_seo_by_story_object(story_object)\n",
        "# score_object\n",
        "\n",
        "# get_recirc_links_from_storyObject(story_object)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2VcLaxlrNo5C",
        "outputId": "9af82fee-60ef-4103-f3b5-b2b2b704181f",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'michigan-supreme-court-trump-2024-primary-ballot'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_eY0JMt8H2f"
      },
      "source": [
        "# Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5y4zb-FV-JS"
      },
      "outputs": [],
      "source": [
        "# @title MAIN WORKING INTERFACE (start this one)\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def int_selectRowResult( theIndex):\n",
        "  print('--------int_selectRowResult')\n",
        "  print(theIndex)\n",
        "\n",
        "def on_select(evt: gr.SelectData):\n",
        "  canonUrl = get_story_canonical_url( search_results_array[evt.index[0]] )\n",
        "  return canonUrl, gr.Tabs.update(selected=0), evt.index[0]\n",
        "\n",
        "def analyze_selected_object(theRow):\n",
        "  print(\"ROW: \"+ theRow)\n",
        "  global search_results_array\n",
        "  return get_html_score_from_story_object( search_results_array[int(theRow)] )\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  gr.Markdown(\"Analyze <B>SEO</B> score for Wapo story.\")\n",
        "  with gr.Tabs() as tabs:\n",
        "    with gr.TabItem(\"URL\", id=0):\n",
        "      with gr.Row():\n",
        "        text_url_input = gr.Textbox(label=\"Enter URL\",\n",
        "            max_lines=1,\n",
        "            placeholder=\"https://www.washingtonpost.com/dc-md-va/2023/10/16/census-race-eliminate-race-box/\",\n",
        "            container=False,\n",
        "        )\n",
        "        analyze_button = gr.Button(\"Analyze URL\")\n",
        "\n",
        "    with gr.TabItem(\"Search story\", id=1):\n",
        "        with gr.Row():\n",
        "          story_search_input = gr.Textbox(label=\"Enter Search\",\n",
        "              max_lines=1,\n",
        "              placeholder=\"What do you want to search for? (one word only please)\",\n",
        "              container=False,\n",
        "          )\n",
        "          story_search_button = gr.Button(\"Search\")\n",
        "\n",
        "        with gr.Row():\n",
        "          search_results_output2 = gr.Dataframe(label=\"Search Results\",\n",
        "              interactive=False,\n",
        "              height=500,\n",
        "          )\n",
        "          selectedRow = gr.Textbox(\n",
        "            visible=False\n",
        "          )\n",
        "\n",
        "  with gr.Tabs() as xtabs:\n",
        "    with gr.TabItem(\"Analysis\", id=3):\n",
        "      with gr.Row():\n",
        "        text_output = gr.HTML()\n",
        "    with gr.TabItem(\"Keywords\", id=4, interactive=False):\n",
        "      with gr.Row():\n",
        "        keyword_output = gr.HTML()\n",
        "        process_keywords_button = gr.Button(\"Keyword Trends\")\n",
        "\n",
        "  search_results_output2.select(on_select, None, [text_url_input, tabs, selectedRow], queue=False).then(\n",
        "      analyze_selected_object, selectedRow, text_output\n",
        "  )\n",
        "\n",
        "  analyze_button.click(get_html_score_from_url, inputs=text_url_input, outputs=text_output, queue=False)\n",
        "  story_search_button.click(interface_search_stories_by_query, inputs=story_search_input, outputs=search_results_output2, queue=False)\n",
        "\n",
        "# demo.queue().launch(debug=True)\n",
        "demo.queue().launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Thnart2Qm22"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkiRNCs5M-dG",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Testing out google speed\n",
        "\n",
        "# https://huggingface.co/spaces/upthrustinc/seoAnalyzerGPT\n",
        "# https://huggingface.co/spaces/upthrustinc/seoAnalyzerGPT/tree/main\n",
        "\n",
        "# CJ THIS WORKS PRETTY GOOD... TELLS BASIC SEO STUFF THAT IS NOT CONTENT RELATED (SO DO WE NEED IT HERE?)\n",
        "#     putting on back shelf for now as it does not fit in scope of project\n",
        "#      also note that the csv file helps give more info on each issue... its pretty neat.\n",
        "from google.colab import userdata\n",
        "\n",
        "def generate_response(website_url, url = \"https://www.googleapis.com/pagespeedonline/v5/runPagespeed\"):\n",
        "    print(\"Website: \" + website_url)\n",
        "    print()\n",
        "    name = website_url.split(\"//\")[1].split(\".\")[1] # Get the name of the website\n",
        "\n",
        "    params = {\n",
        "        \"url\": website_url,\n",
        "        \"key\": userdata.get('GOOGLE_API_KEY_2'),\n",
        "        \"category\": [\"performance\", \"accessibility\", \"best_practices\", \"seo\"]\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        # Process the data as needed\n",
        "        return data\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(\"Error:\", e)\n",
        "\n",
        "def process_data(data):\n",
        "    audits = [data[\"lighthouseResult\"][\"audits\"][i] for i in data[\"lighthouseResult\"][\"audits\"]]\n",
        "    audits_names = [i[\"title\"] for i in audits]\n",
        "\n",
        "    scoresdisplays = [data[\"lighthouseResult\"][\"audits\"][i][\"scoreDisplayMode\"] for i in data[\"lighthouseResult\"][\"audits\"]]\n",
        "\n",
        "    issues = []\n",
        "    for i in audits:\n",
        "        if i[\"scoreDisplayMode\"] != \"notApplicable\" and (i[\"score\"] != 1 and i[\"score\"] != None) and \"details\" in i.keys() and i[\"scoreDisplayMode\"] != \"informative\":\n",
        "            title = i[\"title\"]\n",
        "            desc = i[\"description\"]\n",
        "            item = i[\"details\"][\"items\"][0]\n",
        "            typeOfIssue = i[\"details\"][\"type\"]\n",
        "            dicto = {\"title\": title, \"description\": desc, \"item\": item, \"type\": typeOfIssue}\n",
        "            issues.append(dicto)\n",
        "            print(title)\n",
        "            print(i[\"details\"][\"type\"])\n",
        "            question = f\"Title: {title}\\nDescription: {desc}\\nItem: {item}\"\n",
        "            #print(answer_question(df, question=question, debug=False))\n",
        "            print(\"***********************************\")\n",
        "    return issues\n",
        "\n",
        "googleSpeedInsight = generate_response(\"https://www.washingtonpost.com/health/2023/08/31/marijuana-reclassification-schedule-iii-hhs-dea/\")\n",
        "googleSpeedInsight_Issues = process_data(googleSpeedInsight)\n",
        "print( googleSpeedInsight )\n",
        "\n",
        "\n",
        "# googleSpeedInsight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZeblzODOPGW"
      },
      "outputs": [],
      "source": [
        "# @title TESTING recirc\n",
        "\n",
        "# fullpath = \"https://washpost.arcpublishing.com/ellipsis/api/v1/tags/{key}/automated\"\n",
        "# fullpath = \"https://api.taxonomy.platform.aws.wapo.pub/api/v1/article?url=/sports/2023/10/01/taylor-swift-kelce-chiefs-jets/\"\n",
        "# response = requests.get(fullpath)\n",
        "# print(response.content)\n",
        "\n",
        "\n",
        "# search_results = get_prism_search_data_by_query(\"Lewiston\")\n",
        "# search_object\n",
        "\n",
        "\n",
        "\n",
        "# cleaned_results.append({\n",
        "#         \"name\": \"Carol\",\n",
        "#         \"age\": 22\n",
        "#     })\n",
        "  #     \"text\": \"Taylor Swift comes to Chiefs-Jets, and the NFL gets an even bigger spotlight\",\n",
        "  #     \"topic\": \"/sports\",\n",
        "  #     \"url\": \"https://www.washingtonpost.com/sports/2023/10/01/taylor-swift-kelce-chiefs-jets/\"\n",
        "\n",
        "# my_json_object = json.loads(response.content)\n",
        "# https://api.taxonomy.platform.aws.wapo.pub/api/v1/article?url=/sports/2023/10/01/taylor-swift-kelce-chiefs-jets/\n",
        "\n",
        "# response_object = get_recirc_links_from_ai(\"Taylor Swift comes to Chiefs-Jets, and the NFL gets an even bigger spotlight\", \"/sports\", \"https://www.washingtonpost.com/sports/2023/10/01/taylor-swift-kelce-chiefs-jets/\")\n",
        "# response_object[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8GcjGSe-C4e"
      },
      "outputs": [],
      "source": [
        "# @title test AI summarizing a story\n",
        "\n",
        "# search_results['content_elements'][0]\n",
        "story_html_string = get_full_story_html_api(search_results['content_elements'][6])\n",
        "story_html_string\n",
        "\n",
        "prompt = \"\"\"\n",
        "STORY:\n",
        "{}\n",
        "\n",
        "Please summarize the story in a concise bulleted list, including any specific facts and details.\n",
        "\n",
        "\".\"\"\".format(story_html_string)\n",
        "\n",
        "\n",
        "# story_html_string\n",
        "response = openai.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    # model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert at summarizing and pulling important data from stories.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature=0.0,\n",
        ")\n",
        "\n",
        "print(f\"summary: {response.choices[0].message}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqSwAByxgcwh",
        "outputId": "20087659-b171-4b08-bb50-a1a434db2b48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['marijuana', 'cannabis', 'legalizing', 'legalization', 'reclassification']"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# non_ai_keywords = get_keywords_from_story_object(story_object)\n",
        "# non_ai_keywords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgdRBt9ngyIk",
        "outputId": "f9d926e7-1d3f-4150-d25c-c271038c71a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'score': 'Red',\n",
              " 'value': 'You currently have 0 interstitials and 0 story carousels for your 31 paragraph story.',\n",
              " 'suggestion': 'Ideally have at least 2 interstitials or story carousels for articles at least 12 paragraphs long.'}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# score_object = analyze_seo_by_url(\"https://www.washingtonpost.com/health/2023/08/31/marijuana-reclassification-schedule-iii-hhs-dea/\")\n",
        "score_object['recirc_links']\n",
        "# story_object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OONBlh8LM09M"
      },
      "outputs": [],
      "source": [
        "# @title New HTML Results TEST\n",
        "\n",
        "import IPython\n",
        "\n",
        "# # url = \"https://www.washingtonpost.com/nation/2023/10/31/trump-family-new-york-civil-trial/\"\n",
        "url = \"https://www.washingtonpost.com/politics/2023/12/27/michigan-supreme-court-trump-2024-primary-ballot/\"\n",
        "score_html = get_html_score_from_url( url )\n",
        "IPython.display.HTML(score_html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paeodk1WCXSP"
      },
      "outputs": [],
      "source": [
        "# @title pretty print conversation (NOT SURE I NEED)\n",
        "\n",
        "from termcolor import colored\n",
        "\n",
        "def pretty_print_conversation(messages):\n",
        "    role_to_color = {\n",
        "        \"system\": \"red\",\n",
        "        \"user\": \"green\",\n",
        "        \"assistant\": \"blue\",\n",
        "        \"function\": \"magenta\",\n",
        "    }\n",
        "\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"system\":\n",
        "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"user\":\n",
        "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
        "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
        "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"function\":\n",
        "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WteJjRxTWSFL"
      },
      "outputs": [],
      "source": [
        "story_object = get_prism_data_from_url(\"https://www.washingtonpost.com/health/2023/08/31/marijuana-reclassification-schedule-iii-hhs-dea/\")\n",
        "# get_keywords(story_object)\n",
        "story_html_string = get_full_story_story_object(story_object)\n",
        "story_html_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drydTJQxR4yw"
      },
      "outputs": [],
      "source": [
        "# story_object = get_prism_data_from_url(\"https://www.washingtonpost.com/health/2023/08/31/marijuana-reclassification-schedule-iii-hhs-dea/\")\n",
        "# scoreObject = analyze_seo_by_url(\"https://www.washingtonpost.com/health/2023/08/31/marijuana-reclassification-schedule-iii-hhs-dea/\")\n",
        "pd.DataFrame(get_keywords_from_story_object(story_object))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LLtBMKqwPzLw",
        "K_eY0JMt8H2f"
      ],
      "authorship_tag": "ABX9TyPQH/yvzOtR73rtTWUZxM/M",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}