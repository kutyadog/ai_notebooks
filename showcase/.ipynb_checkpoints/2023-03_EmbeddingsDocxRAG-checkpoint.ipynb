{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kutyadog/ai_notebooks/blob/main/Embeddings_docx_3_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "raw",
      "id": "ad102dfc-c9ab-4f28-a1ba-0f1381c882e6",
      "metadata": {
        "tags": [],
        "id": "ad102dfc-c9ab-4f28-a1ba-0f1381c882e6"
      },
      "source": [
        "# Step 1\n",
        "\n",
        "Download some test data that to add to the AI's knowledge.\n",
        "For this example, lets choose the Small Guitar dataset at Kaggle:\n",
        "https://www.kaggle.com/datasets/thebumpkin/small-guitar-model-dataset-113-models?select=GuitarModels.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "cjO01BPXsw8K"
      },
      "id": "cjO01BPXsw8K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "guitar_data = pd.read_csv('/content/GuitarModels.csv', index_col=0)"
      ],
      "metadata": {
        "id": "NoMxhoJBws9R"
      },
      "id": "NoMxhoJBws9R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(guitar_data.columns)\n",
        "print(guitar_data.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-QCeiatwbVS",
        "outputId": "57b7d58e-35cf-4ae1-fa0b-42ae11d5de7e"
      },
      "id": "8-QCeiatwbVS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Model', 'Introduced', 'NotableUser1', 'NotableUser2', 'NotableUser3',\n",
            "       'Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5',\n",
            "       'Popularity', 'Dates', 'Finish1', 'Finish2', 'Finish3', 'Finish4',\n",
            "       'Finish5'],\n",
            "      dtype='object')\n",
            "Index(['Fender', 'Fender', 'Fender', 'Fender', 'Fender', 'Fender', 'Fender',\n",
            "       'Fender', 'Fender', 'Fender',\n",
            "       ...\n",
            "       'Taylor', 'Taylor', 'Taylor', 'Taylor', 'Taylor', 'Taylor', 'Taylor',\n",
            "       'Taylor', 'Taylor', 'Taylor'],\n",
            "      dtype='object', name='Maker', length=113)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "# pypandoc_binary num2words tiktoken"
      ],
      "metadata": {
        "id": "KTPxaD-uwRoP"
      },
      "id": "KTPxaD-uwRoP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below Cell is from:\n",
        "https://gist.github.com/mandar-karhade/b3f13401b31c24fe48982454c2a6f88a#file-gpt3-api-demo-py"
      ],
      "metadata": {
        "id": "6M_bQXIA1vbH"
      },
      "id": "6M_bQXIA1vbH"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "from openai.embeddings_utils import get_embedding\n",
        "from transformers import GPT2TokenizerFast\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "\n",
        "# get fine_food_reviews data from https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
        "input_datapath = 'fine_food_reviews.csv'\n",
        "df_full = pd.read_csv(input_datapath, index_col=0)\n",
        "df = df_full[['Time', 'ProductId', 'UserId', 'Score', 'Summary', 'Text']]\n",
        "df = df.dropna()\n",
        "df['combined'] = \"Title: \" + df.Summary.str.strip() + \"; Content: \" + df.Text.str.strip()\n",
        "\n",
        "# subsample to 100 most recent reviews and remove samples that are too long\n",
        "df = df.sort_values('Time').tail(100)\n",
        "df.drop('Time', axis=1, inplace=True)\n",
        "\n",
        "# remove reviews that are too long\n",
        "df['n_tokens'] = df.combined.apply(lambda x: len(tokenizer.encode(x)))\n",
        "df = df[df.n_tokens<8000].tail(2)\n",
        "len(df)\n",
        "\n",
        "\n",
        "# you will need the secret key from the OpenAI website\n",
        "# https://beta.openai.com/account/api-keys\n",
        "\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "# This will take just between 5 and 10 minutes\n",
        "def get_embedding(text, engine=\"text-embedding-ada-002\"):\n",
        "   text = text.replace(\"\\n\", \" \")\n",
        "   return openai.Embedding.create(input = [text], model=engine)['data'][0]['embedding']\n",
        "\n",
        "df['ada_embedding'] = df.combined.apply(lambda x: get_embedding(x, engine='text-embedding-ada-002'))\n",
        "\n",
        "print(df[['Summary','Text','ada_embedding']])"
      ],
      "metadata": {
        "id": "7eFarf8y1gAc"
      },
      "id": "7eFarf8y1gAc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63983034-c117-4a01-878b-15e00d83d672",
      "metadata": {
        "id": "63983034-c117-4a01-878b-15e00d83d672",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abe12645-e170-49a9-b851-ab14fb3ef8b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell Run Time:  0.0004050731658935547\n"
          ]
        }
      ],
      "source": [
        "# https://pypi.org/project/pypandoc/\n",
        "# pip install pypandoc_binary\n",
        "\n",
        "import pypandoc\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "\n",
        "start_time=time.time()\n",
        "path ='c:\\\\temp_storage\\\\openai\\\\all-docs'\n",
        "\n",
        "for root, directories, files in os.walk(path , topdown=False):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(\".docx\"):\n",
        "            name =(os.path.join(root,file))\n",
        "            pypandoc.convert_file(name, 'plain', outputfile=name[:-5] +\".txt\")\n",
        "end_time = time.time()\n",
        "duration = end_time - start_time\n",
        "\n",
        "print (\"Cell Run Time: \", duration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c134ebd-9af0-49cf-b454-e4aaa7aec7d7",
      "metadata": {
        "id": "9c134ebd-9af0-49cf-b454-e4aaa7aec7d7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import openai\n",
        "import re\n",
        "import requests\n",
        "import sys\n",
        "from num2words import num2words\n",
        "import numpy as np\n",
        "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
        "import tiktoken\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "openai.organization = userdata.get('OPENAI_ORG')\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "start_time=time.time()\n",
        "path ='/content/openai' #example: 'c:\\\\openai\\\\test'\n",
        "\n",
        "d = []\n",
        "text=\"\"\n",
        "\n",
        "for root, directories, files in os.walk(path , topdown=False):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(\".txt\"):\n",
        "            name =(os.path.join(root,file))\n",
        "            f = open(name, \"r\",encoding=\"utf-8\")\n",
        "            for line in f:\n",
        "                text +=line\n",
        "            f.close()\n",
        "            d.append({'FILE NAME': file ,'CONTENT': text})\n",
        "            pd.DataFrame(d)\n",
        "            metadata_counter = 0\n",
        "            text=\"\"\n",
        "end_time = time.time()\n",
        "duration = end_time - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "682fd607-13f2-43ff-8875-e522c198be69",
      "metadata": {
        "id": "682fd607-13f2-43ff-8875-e522c198be69",
        "outputId": "f7c16da0-1a92-4ac3-e711-a6e8ed7ff33d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38d44acf-af68-438f-8879-5ceacf9d2107\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38d44acf-af68-438f-8879-5ceacf9d2107')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-38d44acf-af68-438f-8879-5ceacf9d2107 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-38d44acf-af68-438f-8879-5ceacf9d2107');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df = pd.DataFrame(d)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0230fbc2-2baf-45c8-9f78-0ddf602ed719",
      "metadata": {
        "id": "0230fbc2-2baf-45c8-9f78-0ddf602ed719"
      },
      "outputs": [],
      "source": [
        "# s is input text\n",
        "def normalize_text(s, sep_token = \" \\n \"):\n",
        "    s = re.sub(r'\\s+',  ' ', s).strip()\n",
        "    s = re.sub(r\". ,\",\"\",s)\n",
        "    # remove all instances of multiple spaces\n",
        "    s = s.replace(\"..\",\".\")\n",
        "    s = s.replace(\". .\",\".\")\n",
        "    s = s.replace(\"\\n\", \"\")\n",
        "    s = s.replace(\"#\",\"\")\n",
        "    s = s.strip()\n",
        "\n",
        "    return s\n",
        "\n",
        "df['CONTENT'] = df[\"CONTENT\"].apply(lambda x : normalize_text(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96b2508b-4b0c-417e-b3ff-0bb4ef738dd2",
      "metadata": {
        "id": "96b2508b-4b0c-417e-b3ff-0bb4ef738dd2"
      },
      "source": [
        "| GENERATION |TOKENIZER    | MAX INPUT TOKENS| KNOWLEDGE CUTOFF|\n",
        "|------------|-------------|-----------------|-----------------|\n",
        "| V2         | cl100k_base | 8191            | Sep 2021        |\n",
        "| V1         | GPT-2/GPT-3 | 2046            | Aug 2020        |\n",
        "\n",
        "\n",
        "https://beta.openai.com/docs/guides/embeddings/what-are-embeddings\n",
        "\n",
        "https://openai.com/blog/new-and-improved-embedding-model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f9487f7-a724-4d20-9c66-d3b85a6e77de",
      "metadata": {
        "id": "0f9487f7-a724-4d20-9c66-d3b85a6e77de",
        "outputId": "7266a3da-238c-4e49-87ac-1852c4efed64"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FILE NAME</th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>n_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DIJKSTRA EWD498 How Do We Tell Truths that Mig...</td>\n",
              "      <td>EWD498 How Do We Tell Truths that Might Hurt? ...</td>\n",
              "      <td>954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bentley 1988 More Programming Pearls.txt</td>\n",
              "      <td>PART I: PROGRAMMING TECHNIQUES I don't have th...</td>\n",
              "      <td>2187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Art of Computer Programming v1.txt</td>\n",
              "      <td>Data usually has much more structural informat...</td>\n",
              "      <td>639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tucker 2004 Computer Science.txt</td>\n",
              "      <td>Computer Science: The Discipline and its Impac...</td>\n",
              "      <td>3262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Chaitin Thinking about Godel and Turing.txt</td>\n",
              "      <td>On the difficulty of computations Two practica...</td>\n",
              "      <td>3812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NPHard Problems.txt</td>\n",
              "      <td>Approximation algorithms have developed in res...</td>\n",
              "      <td>2484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>On Numbers and Games Second Edition.txt</td>\n",
              "      <td>All Numbers Great and Small Whatever is notfor...</td>\n",
              "      <td>2331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Peters 2015 Game Theory.txt</td>\n",
              "      <td>1.3.1 Zero-Sum Games The first example is base...</td>\n",
              "      <td>3287</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           FILE NAME  \\\n",
              "0  DIJKSTRA EWD498 How Do We Tell Truths that Mig...   \n",
              "1           Bentley 1988 More Programming Pearls.txt   \n",
              "2             The Art of Computer Programming v1.txt   \n",
              "3                   Tucker 2004 Computer Science.txt   \n",
              "4        Chaitin Thinking about Godel and Turing.txt   \n",
              "5                                NPHard Problems.txt   \n",
              "6            On Numbers and Games Second Edition.txt   \n",
              "7                        Peters 2015 Game Theory.txt   \n",
              "\n",
              "                                             CONTENT  n_tokens  \n",
              "0  EWD498 How Do We Tell Truths that Might Hurt? ...       954  \n",
              "1  PART I: PROGRAMMING TECHNIQUES I don't have th...      2187  \n",
              "2  Data usually has much more structural informat...       639  \n",
              "3  Computer Science: The Discipline and its Impac...      3262  \n",
              "4  On the difficulty of computations Two practica...      3812  \n",
              "5  Approximation algorithms have developed in res...      2484  \n",
              "6  All Numbers Great and Small Whatever is notfor...      2331  \n",
              "7  1.3.1 Zero-Sum Games The first example is base...      3287  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "df['n_tokens'] = df[\"CONTENT\"].apply(lambda x: len(tokenizer.encode(x)))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19500ec1-9190-4936-a64d-b865c22b1954",
      "metadata": {
        "id": "19500ec1-9190-4936-a64d-b865c22b1954",
        "outputId": "bb00b910-4073-4fb8-f73b-d6e13b495302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tokens: 18956\n",
            "\n",
            "MODEL        VERSION    COST\n",
            "-----------------------------------\n",
            "Ada\t\tv1\t$0.075824\n",
            "Babbage\t\tv1\t$0.09478\n",
            "Curie\t\tv1\t$0.37912\n",
            "Davinci\t\tv1\t$3.7912\n",
            "Ada\t\tv2\t$0.007582\n"
          ]
        }
      ],
      "source": [
        "# Based on https://openai.com/api/pricing/ on 01/29/2023\n",
        "# If you were using this for approximating pricing with Azure OpenAI adjust the values below with: https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/\n",
        "\n",
        "#MODEL\tUSAGE\n",
        "#Ada     v1\t$0.0040 / 1K tokens\n",
        "#Babbage v1\t$0.0050 / 1K tokens\n",
        "#Curie   v1\t$0.0200 / 1K tokens\n",
        "#Davinci v1\t$0.2000 / 1K tokens\n",
        "\n",
        "#MODEL\tUSAGE\n",
        "#Ada     v2\t$0.0004 / 1K tokens\n",
        "#This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models.\n",
        "\n",
        "n_tokens_sum = df['n_tokens'].sum()\n",
        "\n",
        "ada_v1_embeddings_cost = (n_tokens_sum/1000) *.0040\n",
        "babbage_v1_embeddings_cost = (n_tokens_sum/1000) *.0050\n",
        "curie_v1_embeddings_cost = (n_tokens_sum/1000) *.02\n",
        "davinci_v1_embeddings_cost = (n_tokens_sum/1000) *.2\n",
        "\n",
        "ada_v2_embeddings_cost = (n_tokens_sum/1000) *.0004\n",
        "\n",
        "print(\"Number of tokens: \" + str(n_tokens_sum) + \"\\n\")\n",
        "\n",
        "print(\"MODEL        VERSION    COST\")\n",
        "print(\"-----------------------------------\")\n",
        "print(\"Ada\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(ada_v1_embeddings_cost))\n",
        "print(\"Babbage\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(babbage_v1_embeddings_cost))\n",
        "print(\"Curie\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(curie_v1_embeddings_cost))\n",
        "print(\"Davinci\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(davinci_v1_embeddings_cost))\n",
        "print(\"Ada\" + \"\\t\\t\" + \"v2\" + \"\\t$\" + '%.8s' %str(ada_v2_embeddings_cost))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03797d4b-8220-440f-9cbf-ba62856f5c5a",
      "metadata": {
        "id": "03797d4b-8220-440f-9cbf-ba62856f5c5a"
      },
      "outputs": [],
      "source": [
        "def generate_embeddings(text, model=\"text-embedding-ada-002\"):\n",
        "    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
        "\n",
        "df['ada_v2_embedding'] = df.CONTENT.apply(lambda x: generate_embeddings(x, model='text-embedding-ada-002'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72fc2946-ec46-446b-871b-fda1bffb3a6e",
      "metadata": {
        "id": "72fc2946-ec46-446b-871b-fda1bffb3a6e",
        "outputId": "83fc6b34-e903-49a5-c15d-2f9b585da5e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FILE NAME</th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>ada_v2_embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DIJKSTRA EWD498 How Do We Tell Truths that Mig...</td>\n",
              "      <td>EWD498 How Do We Tell Truths that Might Hurt? ...</td>\n",
              "      <td>954</td>\n",
              "      <td>[0.0077162147499620914, -0.0008686786168254912...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bentley 1988 More Programming Pearls.txt</td>\n",
              "      <td>PART I: PROGRAMMING TECHNIQUES I don't have th...</td>\n",
              "      <td>2187</td>\n",
              "      <td>[0.0070382943376898766, 0.0012975081335753202,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Art of Computer Programming v1.txt</td>\n",
              "      <td>Data usually has much more structural informat...</td>\n",
              "      <td>639</td>\n",
              "      <td>[-0.0035451934672892094, 0.030073734000325203,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tucker 2004 Computer Science.txt</td>\n",
              "      <td>Computer Science: The Discipline and its Impac...</td>\n",
              "      <td>3262</td>\n",
              "      <td>[0.016959402710199356, -0.010407204739749432, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Chaitin Thinking about Godel and Turing.txt</td>\n",
              "      <td>On the difficulty of computations Two practica...</td>\n",
              "      <td>3812</td>\n",
              "      <td>[-0.026883335784077644, -0.024646427482366562,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NPHard Problems.txt</td>\n",
              "      <td>Approximation algorithms have developed in res...</td>\n",
              "      <td>2484</td>\n",
              "      <td>[0.015040451660752296, 0.007307712454348803, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>On Numbers and Games Second Edition.txt</td>\n",
              "      <td>All Numbers Great and Small Whatever is notfor...</td>\n",
              "      <td>2331</td>\n",
              "      <td>[-0.001979722874239087, -0.0022908940445631742...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Peters 2015 Game Theory.txt</td>\n",
              "      <td>1.3.1 Zero-Sum Games The first example is base...</td>\n",
              "      <td>3287</td>\n",
              "      <td>[-0.023110942915081978, -0.02227030321955681, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           FILE NAME  \\\n",
              "0  DIJKSTRA EWD498 How Do We Tell Truths that Mig...   \n",
              "1           Bentley 1988 More Programming Pearls.txt   \n",
              "2             The Art of Computer Programming v1.txt   \n",
              "3                   Tucker 2004 Computer Science.txt   \n",
              "4        Chaitin Thinking about Godel and Turing.txt   \n",
              "5                                NPHard Problems.txt   \n",
              "6            On Numbers and Games Second Edition.txt   \n",
              "7                        Peters 2015 Game Theory.txt   \n",
              "\n",
              "                                             CONTENT  n_tokens  \\\n",
              "0  EWD498 How Do We Tell Truths that Might Hurt? ...       954   \n",
              "1  PART I: PROGRAMMING TECHNIQUES I don't have th...      2187   \n",
              "2  Data usually has much more structural informat...       639   \n",
              "3  Computer Science: The Discipline and its Impac...      3262   \n",
              "4  On the difficulty of computations Two practica...      3812   \n",
              "5  Approximation algorithms have developed in res...      2484   \n",
              "6  All Numbers Great and Small Whatever is notfor...      2331   \n",
              "7  1.3.1 Zero-Sum Games The first example is base...      3287   \n",
              "\n",
              "                                    ada_v2_embedding  \n",
              "0  [0.0077162147499620914, -0.0008686786168254912...  \n",
              "1  [0.0070382943376898766, 0.0012975081335753202,...  \n",
              "2  [-0.0035451934672892094, 0.030073734000325203,...  \n",
              "3  [0.016959402710199356, -0.010407204739749432, ...  \n",
              "4  [-0.026883335784077644, -0.024646427482366562,...  \n",
              "5  [0.015040451660752296, 0.007307712454348803, -...  \n",
              "6  [-0.001979722874239087, -0.0022908940445631742...  \n",
              "7  [-0.023110942915081978, -0.02227030321955681, ...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2e67bd6-6fd5-4d2f-889c-d450068a8a0b",
      "metadata": {
        "id": "c2e67bd6-6fd5-4d2f-889c-d450068a8a0b",
        "outputId": "ca143818-1908-4e53-a9be-efd884b4f56c"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "How can I help you?\n",
            "\n",
            " Dangers of BASIC?\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FILE NAME</th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>ada_v2_embedding</th>\n",
              "      <th>similarities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DIJKSTRA EWD498 How Do We Tell Truths that Mig...</td>\n",
              "      <td>EWD498 How Do We Tell Truths that Might Hurt? ...</td>\n",
              "      <td>954</td>\n",
              "      <td>[0.0077162147499620914, -0.0008686786168254912...</td>\n",
              "      <td>0.786783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bentley 1988 More Programming Pearls.txt</td>\n",
              "      <td>PART I: PROGRAMMING TECHNIQUES I don't have th...</td>\n",
              "      <td>2187</td>\n",
              "      <td>[0.0070382943376898766, 0.0012975081335753202,...</td>\n",
              "      <td>0.764150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tucker 2004 Computer Science.txt</td>\n",
              "      <td>Computer Science: The Discipline and its Impac...</td>\n",
              "      <td>3262</td>\n",
              "      <td>[0.016959402710199356, -0.010407204739749432, ...</td>\n",
              "      <td>0.747116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           FILE NAME  \\\n",
              "0  DIJKSTRA EWD498 How Do We Tell Truths that Mig...   \n",
              "1           Bentley 1988 More Programming Pearls.txt   \n",
              "3                   Tucker 2004 Computer Science.txt   \n",
              "\n",
              "                                             CONTENT  n_tokens  \\\n",
              "0  EWD498 How Do We Tell Truths that Might Hurt? ...       954   \n",
              "1  PART I: PROGRAMMING TECHNIQUES I don't have th...      2187   \n",
              "3  Computer Science: The Discipline and its Impac...      3262   \n",
              "\n",
              "                                    ada_v2_embedding  similarities  \n",
              "0  [0.0077162147499620914, -0.0008686786168254912...      0.786783  \n",
              "1  [0.0070382943376898766, 0.0012975081335753202,...      0.764150  \n",
              "3  [0.016959402710199356, -0.010407204739749432, ...      0.747116  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# search embedded docs based on cosine similarity\n",
        "\n",
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
        "\n",
        "def search_docs(df, user_query, top_n=3, to_print=True):\n",
        "    embedding = get_embedding(\n",
        "        user_query,\n",
        "        model=\"text-embedding-ada-002\"\n",
        "    )\n",
        "    df[\"similarities\"] = df.ada_v2_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
        "\n",
        "    res = (\n",
        "        df.sort_values(\"similarities\", ascending=False)\n",
        "        .head(top_n)\n",
        "    )\n",
        "    if to_print:\n",
        "        display(res)\n",
        "    return res\n",
        "\n",
        "question = input(\"How can I help you?\\n\\n\")\n",
        "\n",
        "res = search_docs(df, question, top_n=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a71b3ab0-10dd-4d6d-b8c8-4582ff118ef6",
      "metadata": {
        "id": "a71b3ab0-10dd-4d6d-b8c8-4582ff118ef6",
        "outputId": "b2c462d3-e610-46d2-9a02-6522b0d79ed3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'EWD498 How Do We Tell Truths that Might Hurt? Sometimes we discover unpleasant truths. Whenever we do so, we are in difficulties: suppressing them is scientifically dishonest, so we must tell them, but telling them, however, will fire back on uso If the truths are sufficiently unpalatable, our audience is psycbically incapable of accepting them and we will be written off as totally unrealistic, hopelessly idealistic, dangerously revolutionary, foolishly gullible or what have you. (Besides that, telling such truths is a sure way of making oneself unpopular in many circles, and, as such, it is an act that, in general, is not without personal risks. Vide Galileo Galilei .. ) Computing Science seems to suffer severely from tbis conflict. On the whole, it remains silent and tries to escape tbis conflict by sbifting its attention. (For instance: with respect to COBOL you can really do only one of two tbings: fight the disease or pretend that it does not exist. Most Computer Science Departments have opted for the latter easy way out.) But, Brethren, I ask you: is tbis honest? Is not our prolonged silence fretting away Computing Science\\'s intellectual integrity? Are we decent by remaining silent? If not, how do we speak up? To give you some idea of the scope of the problem I have listed a number of such truths. (N early all computing scientists I know weIl will agree without hesitation to nearly all of them. Yet we allow the world to behave as if we did not know them .. ) * * * Programrning is one of the most difficult branches of applied mathematics; the poorer mathematicians had better remain pure mathematicians. The easiest macbine applications are the technicaljscientific computations. The tools we use have a profound (and devious!) influence on our thinking habits, and, therefore, on our tbinking abilities. 129 130 EWD498 FORTRAN, \"the infantile disorder\", by now nearly 20 years old, is hopelessly inadequate for whatever computer application you have in mind today: it is now too clumsy, too risky, and too expensive to use. PL /1 -\" the fatal disease\" - belongs more to the problem set than to the solution set. It is practically impossible to teach good programming to students that have had a prior exposure to BASIC: as potential programmers they are mentally mutilated beyond hope of regeneration. The use of COBOL cripples the mind; its teaching should, therefore, be regarded as a criminal offence. APL is amistake, carried through to perfection. It is the language of the future for the programming techniques of the past: it creates a new generation of coding bums. The problems of business administration in general and data base management in particular are much too difficult for people that think in IBMerese, compounded with sloppy English. About the use of language: it is impossible to sharpen a pencil with a blunt axe. It is equally vain to try to do it with ten blunt axes instead. Besides a mathematical inclination, an exceptionally good mastery of one\\'s native tongue is the most vital asset of a competent programmer. Many companies that have made themselves dependent on IBM equipment (and in doing so have sold their .soul to the devil) will collapse under the sheer weight of the unmastered complexity of their data processing systems. We can found no scientific discipline, nor a healthy profession, on the technical mistakes of the Department of Defense and, mainly, one computer manufacturer. The use of anthropomorphic terminology when dealing with computing systems is a symptom of professional immaturity. By claiming that they can contribute to software engineering, the soft scientists make themse1ves even more ridiculous. (Not less dangerous, alas!) In spite of its name, software engineering requires (cruelly) hard science for its support. In the good old days physicists repeated each other\\'s experiments, just to be sure. Today they stick to FORTRAN, so that they can share each other\\'s programs, bugs included. Projects promoting programming in \"naturallanguage\" are intrinsically doomed to faiI. How Do We Tell Truths that Might Hurt 131 * * * Isn\\'t tbis list enough to make us uncomfortable? What are we going to do? Return to the order of the day, presumably .. Nuenen, 18th June 1975 PROF. DR. EDSGER W. DIJKSTRA Burroughs Research Fellow ps. If the conjecture \"Y ou would rather that I had not disturbed you by sending you tbis.\" is correct, you may add it to the list of uncomfortable truths. EWD'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res.CONTENT.values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15df48c9-9334-447d-80df-6ef68d1f3704",
      "metadata": {
        "id": "15df48c9-9334-447d-80df-6ef68d1f3704",
        "outputId": "2d7cd330-6aaa-4964-8803-6b26d7f49730"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "How can I help you?\n",
            "\n",
            " Dangers of BASIC?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "A: BASIC can lead to the mental mutilation of potential programmers. Its teaching should be regarded as a criminal offense. It is a language that promotes bad programming habits and limits one's thinking abilities. Additionally, using BASIC can be inefficient and expensive in the long run.\n"
          ]
        }
      ],
      "source": [
        "def search_docs(df, user_query, top_n=3, to_print=True):\n",
        "    embedding = get_embedding(\n",
        "        user_query,\n",
        "        model=\"text-embedding-ada-002\"\n",
        "    )\n",
        "    df[\"similarities\"] = df.ada_v2_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
        "\n",
        "    res = (\n",
        "        df.sort_values(\"similarities\", ascending=False)\n",
        "        .head(top_n)\n",
        "    )\n",
        "    return res\n",
        "\n",
        "res = search_docs(df, question, top_n=1)\n",
        "\n",
        "ai_question = input(\"How can I help you?\\n\\n\")\n",
        "\n",
        "\n",
        "context= res.CONTENT.values\n",
        "completion_model='text-davinci-003'\n",
        "\n",
        "initial_prompt = \"The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.\"\n",
        "\n",
        "combined_prompt = initial_prompt + str(context) + \"Q: \" + ai_question\n",
        "response = openai.Completion.create(model=completion_model, prompt=combined_prompt, max_tokens=100)\n",
        "ai_response = response['choices'][0]['text'].replace('\\n', '').replace(' .', '.').strip()\n",
        "\n",
        "print(\"\\n\"+ ai_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daca8a84-2e9f-4044-ae47-650afe7407ab",
      "metadata": {
        "id": "daca8a84-2e9f-4044-ae47-650afe7407ab",
        "outputId": "a413defa-b180-4784-ee4b-3d82c371e0d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.['EWD498 How Do We Tell Truths that Might Hurt? Sometimes we discover unpleasant truths. Whenever we do so, we are in difficulties: suppressing them is scientifically dishonest, so we must tell them, but telling them, however, will fire back on uso If the truths are sufficiently unpalatable, our audience is psycbically incapable of accepting them and we will be written off as totally unrealistic, hopelessly idealistic, dangerously revolutionary, foolishly gullible or what have you. (Besides that, telling such truths is a sure way of making oneself unpopular in many circles, and, as such, it is an act that, in general, is not without personal risks. Vide Galileo Galilei .. ) Computing Science seems to suffer severely from tbis conflict. On the whole, it remains silent and tries to escape tbis conflict by sbifting its attention. (For instance: with respect to COBOL you can really do only one of two tbings: fight the disease or pretend that it does not exist. Most Computer Science Departments have opted for the latter easy way out.) But, Brethren, I ask you: is tbis honest? Is not our prolonged silence fretting away Computing Science\\'s intellectual integrity? Are we decent by remaining silent? If not, how do we speak up? To give you some idea of the scope of the problem I have listed a number of such truths. (N early all computing scientists I know weIl will agree without hesitation to nearly all of them. Yet we allow the world to behave as if we did not know them .. ) * * * Programrning is one of the most difficult branches of applied mathematics; the poorer mathematicians had better remain pure mathematicians. The easiest macbine applications are the technicaljscientific computations. The tools we use have a profound (and devious!) influence on our thinking habits, and, therefore, on our tbinking abilities. 129 130 EWD498 FORTRAN, \"the infantile disorder\", by now nearly 20 years old, is hopelessly inadequate for whatever computer application you have in mind today: it is now too clumsy, too risky, and too expensive to use. PL /1 -\" the fatal disease\" - belongs more to the problem set than to the solution set. It is practically impossible to teach good programming to students that have had a prior exposure to BASIC: as potential programmers they are mentally mutilated beyond hope of regeneration. The use of COBOL cripples the mind; its teaching should, therefore, be regarded as a criminal offence. APL is amistake, carried through to perfection. It is the language of the future for the programming techniques of the past: it creates a new generation of coding bums. The problems of business administration in general and data base management in particular are much too difficult for people that think in IBMerese, compounded with sloppy English. About the use of language: it is impossible to sharpen a pencil with a blunt axe. It is equally vain to try to do it with ten blunt axes instead. Besides a mathematical inclination, an exceptionally good mastery of one\\'s native tongue is the most vital asset of a competent programmer. Many companies that have made themselves dependent on IBM equipment (and in doing so have sold their .soul to the devil) will collapse under the sheer weight of the unmastered complexity of their data processing systems. We can found no scientific discipline, nor a healthy profession, on the technical mistakes of the Department of Defense and, mainly, one computer manufacturer. The use of anthropomorphic terminology when dealing with computing systems is a symptom of professional immaturity. By claiming that they can contribute to software engineering, the soft scientists make themse1ves even more ridiculous. (Not less dangerous, alas!) In spite of its name, software engineering requires (cruelly) hard science for its support. In the good old days physicists repeated each other\\'s experiments, just to be sure. Today they stick to FORTRAN, so that they can share each other\\'s programs, bugs included. Projects promoting programming in \"naturallanguage\" are intrinsically doomed to faiI. How Do We Tell Truths that Might Hurt 131 * * * Isn\\'t tbis list enough to make us uncomfortable? What are we going to do? Return to the order of the day, presumably .. Nuenen, 18th June 1975 PROF. DR. EDSGER W. DIJKSTRA Burroughs Research Fellow ps. If the conjecture \"Y ou would rather that I had not disturbed you by sending you tbis.\" is correct, you may add it to the list of uncomfortable truths. EWD']Q: Dangers of BASIC?\n"
          ]
        }
      ],
      "source": [
        "print(combined_prompt)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}