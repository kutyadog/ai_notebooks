{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Y1pGuFAokKQ3"
      ],
      "authorship_tag": "ABX9TyMPkbkn6r80zeIdSzVSp0jJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kutyadog/ai_notebooks/blob/main/chatbot_gp_simple_10_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start it all up!"
      ],
      "metadata": {
        "id": "773z7I3agh6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai langchain chromadb\n",
        "!pip install sentence-transformers\n",
        "!pip install -qqq InstructorEmbedding==1.0.1 --progress-bar off\n",
        "!pip install -q gradio\n",
        "# !pip install -qqq chromadb==0.4.5 --progress-bar off"
      ],
      "metadata": {
        "id": "ujT69kzCgiC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "\n",
        "# Setup\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "!mkdir chroma_db"
      ],
      "metadata": {
        "id": "RLGPpEzlghdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# large originally processed here:\n",
        "# https://colab.research.google.com/drive/1ti0oVUwEsecwBFTARLD5I3xPf-f2O9dn#scrollTo=eQlQ4ZWgcXDW\n",
        "\n",
        "Embedding_Model = 'hkunlp/instructor-large' # @param [\"hkunlp/instructor-large\", \"all-MiniLM-L6-v2\", \"3rd option\"] {allow-input: true}\n",
        "Embedding_Func_Type = 'HuggingFaceInstructEmbeddings' # @param [\"HuggingFaceInstructEmbeddings\", \"SentenceTransformerEmbeddings\", \"3rd option\"]\n"
      ],
      "metadata": {
        "id": "YtPuCoUlxaPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if Embedding_Func_Type == 'HuggingFaceInstructEmbeddings':\n",
        "    embedding_function = HuggingFaceInstructEmbeddings(\n",
        "        model_name=Embedding_Model, model_kwargs={\"device\": DEVICE}\n",
        "    )\n",
        "elif Embedding_Func_Type == 'SentenceTransformerEmbeddings':\n",
        "    embedding_function = SentenceTransformerEmbeddings(model_name=Embedding_Model)\n",
        "\n"
      ],
      "metadata": {
        "id": "xmWhgOMv1Joj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load 'formatted_articles.csv' so that you can split it and embed it into db"
      ],
      "metadata": {
        "id": "Y1pGuFAokKQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1aK7p7ZlrX-QD-WWguBPUHfPX5WP-HBy1 -O formatted_articles.csv"
      ],
      "metadata": {
        "id": "EqpQ8jG5p7P0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = CSVLoader(file_path=\"formatted_articles.csv\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "EaazIvbXgfpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split it into chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n"
      ],
      "metadata": {
        "id": "SG76OT10h-tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load docs into Chroma DB\n",
        "db = Chroma.from_documents(docs, embedding_function)"
      ],
      "metadata": {
        "id": "wUkL7e_BjNtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save to disk\n",
        "db2 = Chroma.from_documents(docs, embedding_function, persist_directory=\"./chroma_db\")\n"
      ],
      "metadata": {
        "id": "2sP9KgDPj47B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load already processed db_data into DB\n",
        "For testing I have two processed db files that can be imported. Since they were both split and embedded with two different models, that will also require different embedding functions.\n",
        "\n",
        "You should only run big or small."
      ],
      "metadata": {
        "id": "fbukzLX_kuAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title load smaller db file from google drive & set embedding func\n",
        "# !gdown 1_Uiv4BFK1v10sLYrYXqfAskOOATzmnXL -O chroma_db/chroma.sqlite3 #smaller db file\n",
        "# embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n"
      ],
      "metadata": {
        "id": "EdDcXpjao6KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title load largest db file from google drive & set embedding func\n",
        "# create the open-source embedding function\n",
        "\n",
        "!gdown 1swt3Wt5l6_2cGdrWvjSnUKYw7OwmpAT3 -O chroma_db/chroma.sqlite3 #larger db file\n",
        "\n",
        "#this is for the larger db file\n",
        "# embedding_function = HuggingFaceInstructEmbeddings(\n",
        "#     model_name=\"hkunlp/instructor-large\", model_kwargs={\"device\": DEVICE}\n",
        "# )"
      ],
      "metadata": {
        "id": "ttfBV9LTiTtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf20b26-1f7c-4072-c62b-92212be3d392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1swt3Wt5l6_2cGdrWvjSnUKYw7OwmpAT3\n",
            "To: /content/chroma_db/chroma.sqlite3\n",
            "\r  0% 0.00/20.9M [00:00<?, ?B/s]\r 88% 18.4M/20.9M [00:00<00:00, 182MB/s]\r100% 20.9M/20.9M [00:00<00:00, 191MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title then run this\n",
        "# load from disk\n",
        "db = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_function)\n",
        "db.get()\n"
      ],
      "metadata": {
        "id": "GS49bYVAgoe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query Db for similar embeddings"
      ],
      "metadata": {
        "id": "j3bEYj08go3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# c845f345-e095-4469-8eca-19a1e1d34bcb <--name of dir in chroma_db dir\n",
        "\n",
        "# query the DB\n",
        "query = \"How can i change my 401k?\"\n",
        "docs = db.similarity_search(query)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4G8rZ99TgovU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print results\n",
        "print(docs[2].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40lc8lpGgoo-",
        "outputId": "1524c4a2-1696-458c-9e41-5a1c743c926f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context: The 401(k) plan can help you invest for a comfortable retirement. The plan has the following principal features: If eligible, you may participate in the plan immediately upon hire and, through convenient payroll deductions, you can invest a portion of your pay on a pre-tax basis before federal, state and local income taxes are imposed. You also have the option to make Roth 401(k) contributions and to convert your pre-tax and traditional after-tax assets to Roth assets. Roth 401(k) contributions do not reduce your taxes when you make the contribution, but they accumulate tax-free, and if you hold your Roth contributions in your account until maturity, the investment earnings are never taxed. You also have the option to make “traditional” after-tax contributions to the plan. Earnings on such contributions accumulate on a tax-free basis until withdrawn. (This is not the same as Roth contributions.) If you are age 50 or older, you may make additional pre-tax or Roth 401(k) contributions (of up to $7,500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interface"
      ],
      "metadata": {
        "id": "aFgivdCrhRGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def ask_question(question):\n",
        "  docs = db.similarity_search(query)\n",
        "  return docs[0].page_content\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=ask_question,\n",
        "    # inputs=[\"text\", \"checkbox\", gr.Slider(0, 100)],\n",
        "    inputs=[\"text\"],\n",
        "    # outputs=[\"text\", \"number\"],\n",
        "    outputs = ['html']\n",
        ")\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "W5v-sRG0hUCy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}