{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kutyadog/ai_notebooks/blob/main/llama_2_and_langchain_GP_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests - Sept 2023"
      ],
      "metadata": {
        "id": "xJeENhenRcAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# source\n",
        "# https://github.com/curiousily/Get-Things-Done-with-Prompt-Engineering-and-LangChain/blob/master/13.chat-with-multiple-pdfs-using-llama-2-and-langchain.ipynb\n",
        "\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "AFZMjbPtyXl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee88a7d2-de87-4f80-f2b8-f29ae3322299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IuxHsjZrJqO2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQlQ4ZWgcXDW"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqqq pip --progress-bar off\n",
        "!pip install -qqq torch==2.0.1 --progress-bar off\n",
        "!pip install -qqq transformers==4.31.0 --progress-bar off\n",
        "!pip install -qqq langchain==0.0.266 --progress-bar off\n",
        "!pip install -qqq chromadb==0.4.5 --progress-bar off\n",
        "!pip install -qqq pypdf==3.15.0 --progress-bar off\n",
        "!pip install -qqq xformers==0.0.20 --progress-bar off\n",
        "!pip install -qqq sentence_transformers==2.2.2 --progress-bar off\n",
        "!pip install -qqq InstructorEmbedding==1.0.1 --progress-bar off\n",
        "!pip install -qqq pdf2image==1.16.3 --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/PanQiWei/AutoGPTQ/releases/download/v0.4.1/auto_gptq-0.4.1+cu118-cp310-cp310-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "ecTRR8hwhn0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq auto_gptq-0.4.1+cu118-cp310-cp310-linux_x86_64.whl --progress-bar off"
      ],
      "metadata": {
        "id": "C0_Fa50LkfoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install poppler-utils"
      ],
      "metadata": {
        "id": "t7ShwfeTubDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from auto_gptq import AutoGPTQForCausalLM\n",
        "from langchain import HuggingFacePipeline, PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "# from pdf2image import convert_from_path\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "# from langchain.agents import create_csv_agent\n",
        "\n",
        "from transformers import AutoTokenizer, TextStreamer, pipeline\n",
        "\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "vH5IpjeNflMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "jiX57tzWOJAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title prep for all data\n",
        "embeddings = HuggingFaceInstructEmbeddings(\n",
        "    model_name=\"hkunlp/instructor-large\", model_kwargs={\"device\": DEVICE}\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "OQm1m0Me0XHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title load embeddings database\n",
        "# !gdown 1v-Rn1FVU1pLTAQEgm0N9oB6cExMoebZr -O pdfs/tesla-earnings-report.pdf\n",
        "# !gdown 1Xc890jrQvCExAkryVWAttsv1DBLdVefN -O pdfs/nvidia-earnings-report.pdf\n",
        "# !gdown 1Epz-SQ3idPpoz75GlTzzomag8gplzLv8 -O pdfs/meta-earnings-report.pdf\n",
        "\n",
        "# !gdown 1aK7p7ZlrX-QD-WWguBPUHfPX5WP-HBy1 -O formatted_articles.csv\n",
        "!mkdir db\n",
        "!gdown 1swt3Wt5l6_2cGdrWvjSnUKYw7OwmpAT3 -O db/chroma.sqlite3\n"
      ],
      "metadata": {
        "id": "dZtUHaJOqH5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a80d732-e96d-4900-8a43-a204c8eb03a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1swt3Wt5l6_2cGdrWvjSnUKYw7OwmpAT3\n",
            "To: /content/db/chroma.sqlite3\n",
            "100% 20.9M/20.9M [00:00<00:00, 77.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Redo embeddings by loading question csv\n",
        "# meta_images = convert_from_path(\"pdfs/meta-earnings-report.pdf\", dpi=88)\n",
        "# meta_images = convert_from_path(\"/content/formatted_articles.csv\", dpi=88)\n",
        "# meta_images[0]\n",
        "\n",
        "loader = CSVLoader(file_path=\"formatted_articles.csv\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "a9X4Fbv8ugOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nvidia_images = convert_from_path(\"pdfs/nvidia-earnings-report.pdf\", dpi=88)\n",
        "# nvidia_images[0]"
      ],
      "metadata": {
        "id": "We2A7lVtukAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tesla_images = convert_from_path(\"pdfs/tesla-earnings-report.pdf\", dpi=88)\n",
        "# tesla_images[0]"
      ],
      "metadata": {
        "id": "yL1bVMC2twkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf \"db\""
      ],
      "metadata": {
        "id": "6ywUvMDqZFf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loader = PyPDFDirectoryLoader(\"pdfs\")\n",
        "# docs = loader.load()\n",
        "# len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQmhREpeOInh",
        "outputId": "8866fd8b-cf6d-4e5e-a4ab-ff9eb5eae4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFztsob3WO3x",
        "outputId": "0ce08273-53d9-42c2-9c12-8bb6abbdddfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2934"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This takes About 4 minutes - best to find a way to save it as csv\n",
        "%%time\n",
        "db = Chroma.from_documents(texts, embeddings, persist_directory=\"db\")"
      ],
      "metadata": {
        "id": "ESFJOOYEWTX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87bd4e97-7c8f-4b48-b02f-415101c6b831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3min 58s, sys: 3.82 s, total: 4min 2s\n",
            "Wall time: 4min 38s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load uploaded db\n",
        "db = Chroma(persist_directory='./db/chroma', embedding_function=embeddings)\n",
        "\n",
        "# test it out to find stuffs\n",
        "docs = db.similarity_search(\"how can I change my 401k?\")\n",
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppFScN0sdYNf",
        "outputId": "d57d2660-5504-4477-c121-731645b703f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Llama 2 13B"
      ],
      "metadata": {
        "id": "GcylvlF60r_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
        "model_basename = \"model\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "\n",
        "model = AutoGPTQForCausalLM.from_quantized(\n",
        "    model_name_or_path,\n",
        "    revision=\"gptq-4bit-128g-actorder_True\",\n",
        "    model_basename=model_basename,\n",
        "    use_safetensors=True,\n",
        "    trust_remote_code=True,\n",
        "    inject_fused_attention=False,\n",
        "    device=DEVICE,\n",
        "    quantize_config=None,\n",
        ")"
      ],
      "metadata": {
        "id": "DrSTLMQbfjFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "k6yLtagJfvG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
        "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
        "\n",
        "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def generate_prompt(prompt: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT) -> str:\n",
        "    return f\"\"\"\n",
        "[INST] <<SYS>>\n",
        "{system_prompt}\n",
        "<</SYS>>\n",
        "\n",
        "{prompt} [/INST]\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "NKUo_0gxRD-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "5H6rPBpEAALY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=1024,\n",
        "    temperature=0,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=1.15,\n",
        "    streamer=streamer,\n",
        ")"
      ],
      "metadata": {
        "id": "ZYaQDkDvVvIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e54e57-ae5d-4038-edae-a628fdd12ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'LlamaGPTQForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(pipeline=text_pipeline, model_kwargs={\"temperature\": 0})"
      ],
      "metadata": {
        "id": "s0sKzP77ZCok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\n",
        "\n",
        "template = generate_prompt(\n",
        "    \"\"\"\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\",\n",
        "    system_prompt=SYSTEM_PROMPT,\n",
        ")"
      ],
      "metadata": {
        "id": "J3RKlMe4DNMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
      ],
      "metadata": {
        "id": "pJpTuSEoDDEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 2}),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        ")"
      ],
      "metadata": {
        "id": "0DC-RU6DZCIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat with Multiple PDFs"
      ],
      "metadata": {
        "id": "J7IWZ6H1ax4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain(\"When was george washington born?\")"
      ],
      "metadata": {
        "id": "_BR5nBf_fPao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237ef357-e295-455c-9209-7c02a779da63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Based on the provided context, I cannot answer the question as there is no mention of George Washington's birthdate or any other relevant information about his life. The text only mentions the name \"George Washington\" and provides contact information for the Washington Post. Therefore, I do not have enough information to provide a correct answer to the question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result[\"source_documents\"])\n",
        "print( result[\"source_documents\"])"
      ],
      "metadata": {
        "id": "UyyiaN0yZ6LN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f7036a-15df-4e06-f662-45a89b3f5e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='context: You can make changes to your 401(k) at any time. <b>Changing your savings rate</b> Go to&nbsp;<a href=\"https://guidepost.washpost.com/pf/home\">GuidePost&nbsp;</a>&gt; Okta apps &gt;&nbsp;<a href=\"https://washpost.okta.com/home/thewashingtonpostandcompaniesprod_vanguard_3/0oa1e7vb7q8XtIIUx0h8/aln1e7vk9ba4Tgt050h8\">Vanguard</a>. Once you are logged in to your account in our plan, select MANAGE MY MONEY &gt; Change My Paycheck Deduction. Please confirm paycheck deductions from your payslip on or after the effective date. <b>Adjusting your investments</b> To change how your future contributions are invested, go to <a href=\"https://guidepost.washpost.com/pf/home\">GuidePost&nbsp;</a>&gt; Okta apps &gt; <a href=\"https://washpost.okta.com/home/thewashingtonpostandcompaniesprod_vanguard_3/0oa1e7vb7q8XtIIUx0h8/aln1e7vk9ba4Tgt050h8\">Vanguard</a>. Once you’re logged in select MANAGE MY MONEY &gt; Change my investments &gt; Change paycheck investment mix. Once you complete this step, you’ll be asked if you want', metadata={'row': 411, 'source': '/content/formatted_articles.csv'}), Document(page_content='title: 401(k) Changes\\nurl: https://guidepost.washpost.com/pf/benefits_and_resources/my_benefits/enroll_or_change_benefits/anytime_benefits/beneficiary-changes\\nlast_modified: 2020-08-26\\ndescription:', metadata={'row': 411, 'source': '/content/formatted_articles.csv'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"source_documents\"][0].page_content)"
      ],
      "metadata": {
        "id": "60qpCy_haA3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf953bf-99a3-4d87-8ff0-9cbfaf23e1a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context: You can make changes to your 401(k) at any time. <b>Changing your savings rate</b> Go to&nbsp;<a href=\"https://guidepost.washpost.com/pf/home\">GuidePost&nbsp;</a>&gt; Okta apps &gt;&nbsp;<a href=\"https://washpost.okta.com/home/thewashingtonpostandcompaniesprod_vanguard_3/0oa1e7vb7q8XtIIUx0h8/aln1e7vk9ba4Tgt050h8\">Vanguard</a>. Once you are logged in to your account in our plan, select MANAGE MY MONEY &gt; Change My Paycheck Deduction. Please confirm paycheck deductions from your payslip on or after the effective date. <b>Adjusting your investments</b> To change how your future contributions are invested, go to <a href=\"https://guidepost.washpost.com/pf/home\">GuidePost&nbsp;</a>&gt; Okta apps &gt; <a href=\"https://washpost.okta.com/home/thewashingtonpostandcompaniesprod_vanguard_3/0oa1e7vb7q8XtIIUx0h8/aln1e7vk9ba4Tgt050h8\">Vanguard</a>. Once you’re logged in select MANAGE MY MONEY &gt; Change my investments &gt; Change paycheck investment mix. Once you complete this step, you’ll be asked if you want\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result = qa_chain(\"What is the per share revenue for Tesla during 2023?\")"
      ],
      "metadata": {
        "id": "nKmLM4UTfVmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f224efe1-6492-47d9-f75b-dc30b6097787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I can't determine the per share revenue for Tesla in 2023 based on the information provided. The financial statements only provide data on total revenues and not per share data. Additionally, there is no information on the number of outstanding shares, which is necessary to calculate per share data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result = qa_chain(\"What is the per share revenue for Nvidia during 2023?\")"
      ],
      "metadata": {
        "id": "1k96dxrgfjMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b968b11-7dd6-4956-fbf1-16f1178261fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Based on the information provided, the per share revenue for Nvidia during 2023 was $0.83. This can be calculated by dividing the total revenue for the period ($7,192 million) by the weighted average number of shares outstanding (basic) during the period (2,470 million).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(result[\"source_documents\"][1].page_content)"
      ],
      "metadata": {
        "id": "kpMIspiSahlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result = qa_chain(\"What is the estimated YOY revenue for Meta during 2023?\")"
      ],
      "metadata": {
        "id": "waIck-yefydp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b64329e-2002-4816-a31e-0f157f959e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Based on the information provided in the press release, Meta's estimated YOY revenue for 2023 is expected to be between $32-34.5 billion, which represents an increase of 11-16% over 2022.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result = qa_chain(\"What is the estimated YOY revenue for Tesla during 2023?\")"
      ],
      "metadata": {
        "id": "nq6cf8vof6wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result = qa_chain(\"What is the estimated YOY revenue for Nvidia during 2023?\")"
      ],
      "metadata": {
        "id": "SIFTDoxzgY07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d231cabf-8c35-4a16-d660-9baf27280ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Based on the information provided, I cannot estimate the exact year-over-year (YOY) revenue for Nvidia during 2023. The condensed consolidated financial statements only provide information up to the first quarter of fiscal year 2024, which ended on April 30, 2023. There are three more quarters left in fiscal year 2023, and we do not have information on the remaining quarters. Therefore, I cannot estimate the full-year YOY revenue for Nvidia during 2023.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result = qa_chain(\n",
        "#     \"Which company is more profitable during 2023 Meta, Nvidia or Tesla and why?\"\n",
        "# )"
      ],
      "metadata": {
        "id": "cxp167huggFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b3eae5-2504-4520-c11d-d74d7547baf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I cannot determine which company is more profitable during 2023 between Meta, Nvidia, and Tesla based on the information provided. The passage only discusses Nvidia's financial condition and results of operations, but does not provide any information about Meta or Tesla's financial performance during 2023. Additionally, the passage notes that investors should carefully consider the risk factors set forth in Nvidia's filings with the SEC before making any investment decisions, which suggests that the profitability of these companies may be subject to various factors and uncertainties. Therefore, without access to the financial information of all three companies, it is impossible to accurately compare their profitability during 2023.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result = qa_chain(\n",
        "#     \"Choose one company to invest (Tesla, Nvidia or Meta) to maximize your profits for the long term (10+ years)?\"\n",
        "# )"
      ],
      "metadata": {
        "id": "vRuJYwSbgpij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36847349-76dd-429d-ea56-1927094de4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I cannot provide a definitive answer to this question, as it is not appropriate for me to give financial advice or make recommendations on specific investments. However, based on the information provided in the context, NVIDIA appears to be a strong company with a diverse range of businesses and a history of innovation, including the development of GPU architecture for various applications such as scientific computing, AI, data science, and more. Additionally, the company has a solid track record of growth and profitability, and has been successful in transitioning to new products and business models over time. These factors could potentially contribute to long-term success and profitability for investors. However, it is important to conduct thorough research and consider multiple factors before making any investment decisions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "- [Tesla Quarterly Report (Jul 21, 2023)](https://ir.tesla.com/_flysystem/s3/sec/000095017023033872/tsla-20230630-gen.pdf)\n",
        "- [Meta Q2 2023 Earnings (Jul 26, 2023)](https://s21.q4cdn.com/399680738/files/doc_financials/2023/q2/Meta-06-30-2023-Exhibit-99-1-FINAL.pdf)\n",
        "- [Nvidia Fiscal Q1 2024](https://s201.q4cdn.com/141608511/files/doc_financials/2024/q1/ecefb2b2-efcb-45f3-b72b-212d90fcd873.pdf)"
      ],
      "metadata": {
        "id": "hdyKOEdRg2hc"
      }
    }
  ]
}